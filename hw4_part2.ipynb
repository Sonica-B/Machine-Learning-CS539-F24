{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonica-B/Machine-Learning-CS539-F24/blob/hw4/hw4_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XHd5ExbUIUg"
      },
      "source": [
        "# Pytorch with the MNIST Dataset - MINST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0COdCqT2Wk"
      },
      "source": [
        "## import libraries\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXCYmmjyVRq5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "757f1516-3a7a-4c1f-d64b-08011d90849e"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=64 #changed from 32 to 64\n",
        "args['test_batch_size']=64\n",
        "args['epochs']=1  #The number of Epochs is the number of times you go through the full dataset.\n",
        "args['lr']=0.01 #Learning rate is how fast it will decend.\n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=10\n",
        "args['cuda']=True #if the computer has a GPU, type True, otherwise, False"
      ],
      "metadata": {
        "id": "Fp3VqwxU9teg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is adopted from the pytorch examples repository. It is licensed under BSD 3-Clause \"New\" or \"Revised\" License. Source: https://github.com/pytorch/examples/ LICENSE: https://github.com/pytorch/examples/blob/master/LICENSE"
      ],
      "metadata": {
        "id": "ys8268Yr6sAC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhuQyU7AYE6K"
      },
      "source": [
        "## Load Dataset\n",
        "The first step before training the model is to import the data. We will use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSjjLXrOVWBy"
      },
      "source": [
        "## transformations\n",
        "transform = transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])\n",
        "\n",
        "## download and load training dataset\n",
        "trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
        "\n",
        "## download and load testing dataset\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=args['test_batch_size'], shuffle=True, **kwargs)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nZwZukWXUDn"
      },
      "source": [
        "## Exploring the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW_loWKga7CH"
      },
      "source": [
        "Let's check what the train and test dataset contains. I will use `matplotlib` to print out some of the images from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWd9Pt1Ca6K9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "820aa6e4-64ab-4b72-a5f3-44b986747f9c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "## functions to show an image\n",
        "def imshow(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "## get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "## show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9mXAVmRvhrq"
      },
      "source": [
        "Let's check the dimensions of a batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNFKWz1GZ4R5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8dcf1f22-9147-4630-9052-d05ad8fec849"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    print(\"Image batch dimensions:\", images.shape)\n",
        "    print(\"Image label dimensions:\", labels.shape)\n",
        "    break"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([64, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmaCTw5tXowR"
      },
      "source": [
        "## The Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Function Without CNN Layer "
      ],
      "metadata": {
        "id": "DIczChaLLPMW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IYnV4ZBa3cJ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=x.view(-1,784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        #Softmax gets probabilities.\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "Function With 1 CNN Layer "
      ],
      "metadata": {
        "id": "p5qUjSHVLo_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # First convolutional layer: 1 input channel, 32 output channels\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        #x=x.view(-1,784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        #Softmax gets probabilities.\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "tRkFvePEZCHd"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "Function With 2 CNN Layer \n"
      ],
      "metadata": {
        "id": "-896QPKAL0xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # First convolutional layer: 1 input channel, 28 output channels\n",
        "        self.conv1 = nn.Conv2d(1, 28, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Second convolutional layer: 28 input channels, 32 output channels\n",
        "        self.conv2 = nn.Conv2d(28, 32, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        # Dimensionality reduction layer to match 784 inputs for fc1\n",
        "        self.dim_reducer = nn.Linear(1568, 784)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        #x=x.view(-1,784)\n",
        "        # Apply dimensionality reduction to match input size of fc1\n",
        "        x = self.dim_reducer(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        #Softmax gets probabilities.\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "gkjztD_9LzH4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1poxFYqftKov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f542be17-58a7-4a8d-a4eb-c84dc70fe39f"
      },
      "source": [
        "## test the model with 1 batch\n",
        "model = Net()\n",
        "#print(model)\n",
        "for images, labels in train_loader:\n",
        "    print(\"batch size:\", args['batch_size'])\n",
        "    out = model(images)\n",
        "    print(out.shape)\n",
        "    break"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: 64\n",
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h_3eZQRHV_P"
      },
      "source": [
        "## Training the Model\n",
        "Now we are ready to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E59hwZlAIVcL"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable.\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch.\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable\n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically.\n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          if args['cuda']:\n",
        "              data, target = data.cuda(), target.cuda()\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          test_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
        "          pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "          correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "dmoO9DlN_Ir6"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Results - Without CNN Layer "
      ],
      "metadata": {
        "id": "BUdNt6GslHU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gx5TOuwzlqjz",
        "outputId": "f02746a4-973d-49d6-9795-cef737be1887"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.320207\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.004853\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.742395\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 1.367994\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.218946\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.966231\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.834849\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.647816\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.663867\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.536120\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.643585\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.634093\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.555330\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.452556\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.601981\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.471001\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.528277\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.426070\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.525767\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.447959\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.399419\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.586153\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.410921\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.261390\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.315323\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.427393\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.476579\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.443073\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.447854\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.289942\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.575735\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.231088\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.288677\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.252904\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.365159\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.359134\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.308817\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.333603\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.389700\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.383618\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.272328\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.463397\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.390437\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.311975\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.404672\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.347380\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.444060\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.288145\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.241818\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.265705\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.447085\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.277420\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.371893\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.163706\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.464842\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.229153\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.518350\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.445439\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.527507\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.696661\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.307871\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.407040\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.230685\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.396762\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.344710\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.286728\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.328665\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.177785\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.249442\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.380182\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.189400\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.239653\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.404898\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.338228\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.295037\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.184089\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.220591\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.232725\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.144263\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.197499\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.275229\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.408600\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.088620\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.204144\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.231934\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.196021\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.390102\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.335723\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.234095\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.178172\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.392131\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.276648\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.290332\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.238533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.2561, Accuracy: 9262/10000 (93%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Results - With 1 CNN Layer "
      ],
      "metadata": {
        "id": "gpZoNHZDlkps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "id": "PQcWwu_A_2gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ea2115-3d8c-4c8f-e067-b07c3557de37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.324679\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.801129\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.220307\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.798972\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.553820\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.446185\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.432305\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.603873\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.542304\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.427222\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.399443\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.366460\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.420878\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.332036\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.364819\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.280376\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.412950\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.326366\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.368769\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.204294\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.216059\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.526026\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.381680\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.335499\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.266350\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.452274\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.277955\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.347437\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.223950\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.182515\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.146121\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.180061\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.209676\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.254402\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.200449\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.132338\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.232276\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.368520\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.193264\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.232754\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.274308\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.242453\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.378693\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.157882\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.210491\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.209797\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.111751\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.329846\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.160969\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.203546\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.175185\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.101511\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.332586\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.215917\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.338527\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.160138\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.213011\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.165414\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.086370\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.078025\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.195158\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.134542\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.145388\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.205886\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.144490\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.304415\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.288605\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.060211\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.095719\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.151825\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.098358\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.265757\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.203382\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.226423\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.325331\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.129530\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.039108\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.231548\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.316183\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.268469\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.126358\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.221436\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.197918\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.050993\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.140745\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.094131\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.077014\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.159227\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.130148\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.103697\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.189535\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.150114\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.149976\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.158036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1375, Accuracy: 9593/10000 (96%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Experimenting with different set of HyperParameters and Network Topologies\n",
        "\n",
        "1) Results - With 2 CNN Layer "
      ],
      "metadata": {
        "id": "KrsN13nekkjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "id": "9m3--4A-nDL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c40edaa0-8092-47ad-b81c-8bdbf2f4e58e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303020\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.281819\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.252346\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.223011\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.154228\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.051044\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.949421\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.595366\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.228488\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.982484\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.724905\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.729990\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.590910\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.889242\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.359823\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.503985\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.554815\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.372829\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.392720\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.353639\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.468223\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.415563\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.394513\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.386249\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.479020\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.374048\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.509387\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.275199\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.220288\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.190482\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.437952\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.546517\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.273954\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.327001\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.419312\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.192281\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.349590\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.173149\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.400282\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.396371\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.255573\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.069998\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.234842\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.277792\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.108131\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.263422\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.121483\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.162130\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.079969\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.147537\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.153209\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.189218\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.158108\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.272247\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.264606\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.234035\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.083643\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.171657\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.116725\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.481733\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.126468\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.054077\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.178630\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.319627\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.102561\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.151872\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.220235\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.160888\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.069203\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.137903\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.208397\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.181498\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.095169\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.148019\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.124289\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.168926\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.237950\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.219675\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.188637\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.036207\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.374976\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.096544\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.089064\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.163821\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.055521\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.233503\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.127848\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.283392\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.032731\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.070723\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.055533\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.111102\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.111862\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.241074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1077, Accuracy: 9660/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Results - lr = 0.05, epochs = 10, batch_size = 32  "
      ],
      "metadata": {
        "id": "Wj4gRbfUmlta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UUPdVc-jmjez",
        "outputId": "bb790920-3b5f-4c02-9902-7e3cfbb7c9e8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301962\n",
            "Train Epoch: 1 [320/60000 (1%)]\tLoss: 2.208472\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.628933\n",
            "Train Epoch: 1 [960/60000 (2%)]\tLoss: 1.110343\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.140816\n",
            "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 0.698782\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.438318\n",
            "Train Epoch: 1 [2240/60000 (4%)]\tLoss: 0.517358\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.565106\n",
            "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.205390\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.170630\n",
            "Train Epoch: 1 [3520/60000 (6%)]\tLoss: 0.121782\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.281034\n",
            "Train Epoch: 1 [4160/60000 (7%)]\tLoss: 0.279285\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.298693\n",
            "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.666171\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.111941\n",
            "Train Epoch: 1 [5440/60000 (9%)]\tLoss: 0.082327\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.310517\n",
            "Train Epoch: 1 [6080/60000 (10%)]\tLoss: 0.180887\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.091136\n",
            "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.657411\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.156061\n",
            "Train Epoch: 1 [7360/60000 (12%)]\tLoss: 0.042964\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.124186\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.184898\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.182580\n",
            "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.289423\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.024053\n",
            "Train Epoch: 1 [9280/60000 (15%)]\tLoss: 0.100308\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.163089\n",
            "Train Epoch: 1 [9920/60000 (17%)]\tLoss: 0.149077\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.096751\n",
            "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.040769\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.116152\n",
            "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.261723\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.094267\n",
            "Train Epoch: 1 [11840/60000 (20%)]\tLoss: 0.110332\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.032869\n",
            "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.018617\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.041645\n",
            "Train Epoch: 1 [13120/60000 (22%)]\tLoss: 0.051638\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.114476\n",
            "Train Epoch: 1 [13760/60000 (23%)]\tLoss: 0.375446\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.142212\n",
            "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.130056\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.030462\n",
            "Train Epoch: 1 [15040/60000 (25%)]\tLoss: 0.200791\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.266852\n",
            "Train Epoch: 1 [15680/60000 (26%)]\tLoss: 0.020212\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.043388\n",
            "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.116388\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.239013\n",
            "Train Epoch: 1 [16960/60000 (28%)]\tLoss: 0.111772\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.126547\n",
            "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.033194\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.127795\n",
            "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.188469\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.017969\n",
            "Train Epoch: 1 [18880/60000 (31%)]\tLoss: 0.180876\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.126891\n",
            "Train Epoch: 1 [19520/60000 (33%)]\tLoss: 0.031459\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.030311\n",
            "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.042750\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.151115\n",
            "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.031436\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.058013\n",
            "Train Epoch: 1 [21440/60000 (36%)]\tLoss: 0.019272\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.013196\n",
            "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.073824\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.025581\n",
            "Train Epoch: 1 [22720/60000 (38%)]\tLoss: 0.035975\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.031383\n",
            "Train Epoch: 1 [23360/60000 (39%)]\tLoss: 0.257709\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.005483\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.094636\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.062491\n",
            "Train Epoch: 1 [24640/60000 (41%)]\tLoss: 0.011890\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.118460\n",
            "Train Epoch: 1 [25280/60000 (42%)]\tLoss: 0.087694\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.296451\n",
            "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.012830\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.044183\n",
            "Train Epoch: 1 [26560/60000 (44%)]\tLoss: 0.094018\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.100627\n",
            "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.147833\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.034856\n",
            "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.117354\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.026022\n",
            "Train Epoch: 1 [28480/60000 (47%)]\tLoss: 0.054099\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.174646\n",
            "Train Epoch: 1 [29120/60000 (49%)]\tLoss: 0.080719\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.024279\n",
            "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.016259\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.135122\n",
            "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.111173\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.020886\n",
            "Train Epoch: 1 [31040/60000 (52%)]\tLoss: 0.334697\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.016858\n",
            "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.046671\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.015312\n",
            "Train Epoch: 1 [32320/60000 (54%)]\tLoss: 0.329094\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.011624\n",
            "Train Epoch: 1 [32960/60000 (55%)]\tLoss: 0.004864\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.107101\n",
            "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.027783\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.009060\n",
            "Train Epoch: 1 [34240/60000 (57%)]\tLoss: 0.027420\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.100217\n",
            "Train Epoch: 1 [34880/60000 (58%)]\tLoss: 0.003404\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.018165\n",
            "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.048101\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.063694\n",
            "Train Epoch: 1 [36160/60000 (60%)]\tLoss: 0.133385\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.209006\n",
            "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.058125\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.026874\n",
            "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.183041\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.104411\n",
            "Train Epoch: 1 [38080/60000 (63%)]\tLoss: 0.033659\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.219000\n",
            "Train Epoch: 1 [38720/60000 (65%)]\tLoss: 0.078677\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.007580\n",
            "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.059604\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.167640\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.125079\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.115200\n",
            "Train Epoch: 1 [40640/60000 (68%)]\tLoss: 0.165838\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.067752\n",
            "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.069213\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.152804\n",
            "Train Epoch: 1 [41920/60000 (70%)]\tLoss: 0.109569\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.015995\n",
            "Train Epoch: 1 [42560/60000 (71%)]\tLoss: 0.008230\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.145913\n",
            "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.098551\n",
            "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 0.019108\n",
            "Train Epoch: 1 [43840/60000 (73%)]\tLoss: 0.015765\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.120858\n",
            "Train Epoch: 1 [44480/60000 (74%)]\tLoss: 0.009674\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.134166\n",
            "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.022434\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.022470\n",
            "Train Epoch: 1 [45760/60000 (76%)]\tLoss: 0.059671\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.039897\n",
            "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.027427\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.251473\n",
            "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.009493\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.065886\n",
            "Train Epoch: 1 [47680/60000 (79%)]\tLoss: 0.035159\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.036940\n",
            "Train Epoch: 1 [48320/60000 (81%)]\tLoss: 0.172806\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.169227\n",
            "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.052062\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.010769\n",
            "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.295505\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.073364\n",
            "Train Epoch: 1 [50240/60000 (84%)]\tLoss: 0.002485\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.465221\n",
            "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.037057\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.040558\n",
            "Train Epoch: 1 [51520/60000 (86%)]\tLoss: 0.017866\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.017627\n",
            "Train Epoch: 1 [52160/60000 (87%)]\tLoss: 0.014852\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.223537\n",
            "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.011142\n",
            "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 0.049595\n",
            "Train Epoch: 1 [53440/60000 (89%)]\tLoss: 0.058189\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.007478\n",
            "Train Epoch: 1 [54080/60000 (90%)]\tLoss: 0.007549\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.016921\n",
            "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.003132\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.250912\n",
            "Train Epoch: 1 [55360/60000 (92%)]\tLoss: 0.168366\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.093083\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.040018\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.007420\n",
            "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.022233\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.084864\n",
            "Train Epoch: 1 [57280/60000 (95%)]\tLoss: 0.002721\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.011526\n",
            "Train Epoch: 1 [57920/60000 (97%)]\tLoss: 0.019251\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.079137\n",
            "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.020588\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.043269\n",
            "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.146688\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.009064\n",
            "Train Epoch: 1 [59840/60000 (100%)]\tLoss: 0.243187\n",
            "\n",
            "Test set: Average loss: 0.0542, Accuracy: 9817/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.116595\n",
            "Train Epoch: 2 [320/60000 (1%)]\tLoss: 0.010550\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.247743\n",
            "Train Epoch: 2 [960/60000 (2%)]\tLoss: 0.090089\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.021561\n",
            "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.028847\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.151310\n",
            "Train Epoch: 2 [2240/60000 (4%)]\tLoss: 0.036559\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.006642\n",
            "Train Epoch: 2 [2880/60000 (5%)]\tLoss: 0.022702\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.007477\n",
            "Train Epoch: 2 [3520/60000 (6%)]\tLoss: 0.023493\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.006812\n",
            "Train Epoch: 2 [4160/60000 (7%)]\tLoss: 0.003474\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.036566\n",
            "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.014757\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.028336\n",
            "Train Epoch: 2 [5440/60000 (9%)]\tLoss: 0.001021\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.001729\n",
            "Train Epoch: 2 [6080/60000 (10%)]\tLoss: 0.045504\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.011500\n",
            "Train Epoch: 2 [6720/60000 (11%)]\tLoss: 0.081144\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.007946\n",
            "Train Epoch: 2 [7360/60000 (12%)]\tLoss: 0.020009\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.054111\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.004907\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.032688\n",
            "Train Epoch: 2 [8640/60000 (14%)]\tLoss: 0.059204\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.003176\n",
            "Train Epoch: 2 [9280/60000 (15%)]\tLoss: 0.091764\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.023965\n",
            "Train Epoch: 2 [9920/60000 (17%)]\tLoss: 0.004445\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.004931\n",
            "Train Epoch: 2 [10560/60000 (18%)]\tLoss: 0.011718\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.115989\n",
            "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.444839\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.010278\n",
            "Train Epoch: 2 [11840/60000 (20%)]\tLoss: 0.198113\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.003320\n",
            "Train Epoch: 2 [12480/60000 (21%)]\tLoss: 0.002141\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.192994\n",
            "Train Epoch: 2 [13120/60000 (22%)]\tLoss: 0.043042\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.121044\n",
            "Train Epoch: 2 [13760/60000 (23%)]\tLoss: 0.058983\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.001972\n",
            "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.081341\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.001572\n",
            "Train Epoch: 2 [15040/60000 (25%)]\tLoss: 0.014012\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.004818\n",
            "Train Epoch: 2 [15680/60000 (26%)]\tLoss: 0.018834\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.000272\n",
            "Train Epoch: 2 [16320/60000 (27%)]\tLoss: 0.058536\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.025452\n",
            "Train Epoch: 2 [16960/60000 (28%)]\tLoss: 0.001312\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.003816\n",
            "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.002227\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.000410\n",
            "Train Epoch: 2 [18240/60000 (30%)]\tLoss: 0.069892\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.061256\n",
            "Train Epoch: 2 [18880/60000 (31%)]\tLoss: 0.024776\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.042054\n",
            "Train Epoch: 2 [19520/60000 (33%)]\tLoss: 0.225146\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.014160\n",
            "Train Epoch: 2 [20160/60000 (34%)]\tLoss: 0.006322\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.044349\n",
            "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.001760\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.014957\n",
            "Train Epoch: 2 [21440/60000 (36%)]\tLoss: 0.004353\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.048874\n",
            "Train Epoch: 2 [22080/60000 (37%)]\tLoss: 0.001541\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.201547\n",
            "Train Epoch: 2 [22720/60000 (38%)]\tLoss: 0.028215\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.003429\n",
            "Train Epoch: 2 [23360/60000 (39%)]\tLoss: 0.027442\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.112250\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.001202\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.072476\n",
            "Train Epoch: 2 [24640/60000 (41%)]\tLoss: 0.095464\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.007142\n",
            "Train Epoch: 2 [25280/60000 (42%)]\tLoss: 0.031832\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.018868\n",
            "Train Epoch: 2 [25920/60000 (43%)]\tLoss: 0.038278\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.010893\n",
            "Train Epoch: 2 [26560/60000 (44%)]\tLoss: 0.003015\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.001935\n",
            "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.003190\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.205324\n",
            "Train Epoch: 2 [27840/60000 (46%)]\tLoss: 0.064513\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.004873\n",
            "Train Epoch: 2 [28480/60000 (47%)]\tLoss: 0.003504\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.001052\n",
            "Train Epoch: 2 [29120/60000 (49%)]\tLoss: 0.003995\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.212709\n",
            "Train Epoch: 2 [29760/60000 (50%)]\tLoss: 0.252549\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.004765\n",
            "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.021823\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.008593\n",
            "Train Epoch: 2 [31040/60000 (52%)]\tLoss: 0.021279\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.048301\n",
            "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 0.005330\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.025715\n",
            "Train Epoch: 2 [32320/60000 (54%)]\tLoss: 0.001804\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.002814\n",
            "Train Epoch: 2 [32960/60000 (55%)]\tLoss: 0.231839\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.003385\n",
            "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.007517\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.008939\n",
            "Train Epoch: 2 [34240/60000 (57%)]\tLoss: 0.000626\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.002568\n",
            "Train Epoch: 2 [34880/60000 (58%)]\tLoss: 0.056465\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.397443\n",
            "Train Epoch: 2 [35520/60000 (59%)]\tLoss: 0.005391\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.059629\n",
            "Train Epoch: 2 [36160/60000 (60%)]\tLoss: 0.017672\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.047950\n",
            "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.149371\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.001908\n",
            "Train Epoch: 2 [37440/60000 (62%)]\tLoss: 0.006638\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.011556\n",
            "Train Epoch: 2 [38080/60000 (63%)]\tLoss: 0.080485\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.020634\n",
            "Train Epoch: 2 [38720/60000 (65%)]\tLoss: 0.006380\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.015378\n",
            "Train Epoch: 2 [39360/60000 (66%)]\tLoss: 0.010057\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.001868\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.043178\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.081386\n",
            "Train Epoch: 2 [40640/60000 (68%)]\tLoss: 0.003808\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.010328\n",
            "Train Epoch: 2 [41280/60000 (69%)]\tLoss: 0.091555\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.000250\n",
            "Train Epoch: 2 [41920/60000 (70%)]\tLoss: 0.000997\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.099513\n",
            "Train Epoch: 2 [42560/60000 (71%)]\tLoss: 0.001928\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.233444\n",
            "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.002210\n",
            "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 0.001958\n",
            "Train Epoch: 2 [43840/60000 (73%)]\tLoss: 0.002351\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.010229\n",
            "Train Epoch: 2 [44480/60000 (74%)]\tLoss: 0.065446\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003719\n",
            "Train Epoch: 2 [45120/60000 (75%)]\tLoss: 0.069313\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.009601\n",
            "Train Epoch: 2 [45760/60000 (76%)]\tLoss: 0.223815\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.013631\n",
            "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.113892\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.070113\n",
            "Train Epoch: 2 [47040/60000 (78%)]\tLoss: 0.081158\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.009143\n",
            "Train Epoch: 2 [47680/60000 (79%)]\tLoss: 0.024780\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.004741\n",
            "Train Epoch: 2 [48320/60000 (81%)]\tLoss: 0.036379\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.043790\n",
            "Train Epoch: 2 [48960/60000 (82%)]\tLoss: 0.058529\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.001158\n",
            "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.030036\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.073952\n",
            "Train Epoch: 2 [50240/60000 (84%)]\tLoss: 0.009934\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.007074\n",
            "Train Epoch: 2 [50880/60000 (85%)]\tLoss: 0.005166\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.016364\n",
            "Train Epoch: 2 [51520/60000 (86%)]\tLoss: 0.008128\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.005999\n",
            "Train Epoch: 2 [52160/60000 (87%)]\tLoss: 0.022164\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.001963\n",
            "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.008483\n",
            "Train Epoch: 2 [53120/60000 (89%)]\tLoss: 0.053024\n",
            "Train Epoch: 2 [53440/60000 (89%)]\tLoss: 0.018093\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.002634\n",
            "Train Epoch: 2 [54080/60000 (90%)]\tLoss: 0.005597\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.007718\n",
            "Train Epoch: 2 [54720/60000 (91%)]\tLoss: 0.004857\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.148574\n",
            "Train Epoch: 2 [55360/60000 (92%)]\tLoss: 0.089982\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.022837\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.003182\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.063111\n",
            "Train Epoch: 2 [56640/60000 (94%)]\tLoss: 0.005230\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.007779\n",
            "Train Epoch: 2 [57280/60000 (95%)]\tLoss: 0.001689\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.196225\n",
            "Train Epoch: 2 [57920/60000 (97%)]\tLoss: 0.010506\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.007637\n",
            "Train Epoch: 2 [58560/60000 (98%)]\tLoss: 0.009485\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.047896\n",
            "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.000186\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.070834\n",
            "Train Epoch: 2 [59840/60000 (100%)]\tLoss: 0.007046\n",
            "\n",
            "Test set: Average loss: 0.0472, Accuracy: 9853/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.003272\n",
            "Train Epoch: 3 [320/60000 (1%)]\tLoss: 0.002559\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.022697\n",
            "Train Epoch: 3 [960/60000 (2%)]\tLoss: 0.012620\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.004396\n",
            "Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.302099\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.013806\n",
            "Train Epoch: 3 [2240/60000 (4%)]\tLoss: 0.010906\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.003885\n",
            "Train Epoch: 3 [2880/60000 (5%)]\tLoss: 0.033616\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.005764\n",
            "Train Epoch: 3 [3520/60000 (6%)]\tLoss: 0.011264\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.020960\n",
            "Train Epoch: 3 [4160/60000 (7%)]\tLoss: 0.026232\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.080319\n",
            "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.033322\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.041805\n",
            "Train Epoch: 3 [5440/60000 (9%)]\tLoss: 0.004581\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.015897\n",
            "Train Epoch: 3 [6080/60000 (10%)]\tLoss: 0.135840\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.009993\n",
            "Train Epoch: 3 [6720/60000 (11%)]\tLoss: 0.002462\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.094951\n",
            "Train Epoch: 3 [7360/60000 (12%)]\tLoss: 0.038269\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.029674\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.020935\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.002722\n",
            "Train Epoch: 3 [8640/60000 (14%)]\tLoss: 0.000466\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.014545\n",
            "Train Epoch: 3 [9280/60000 (15%)]\tLoss: 0.108827\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.000606\n",
            "Train Epoch: 3 [9920/60000 (17%)]\tLoss: 0.120040\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.000734\n",
            "Train Epoch: 3 [10560/60000 (18%)]\tLoss: 0.001431\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.083919\n",
            "Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.045245\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.001584\n",
            "Train Epoch: 3 [11840/60000 (20%)]\tLoss: 0.000210\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.032944\n",
            "Train Epoch: 3 [12480/60000 (21%)]\tLoss: 0.009218\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.003338\n",
            "Train Epoch: 3 [13120/60000 (22%)]\tLoss: 0.009032\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.074844\n",
            "Train Epoch: 3 [13760/60000 (23%)]\tLoss: 0.098381\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.116484\n",
            "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.031281\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.001528\n",
            "Train Epoch: 3 [15040/60000 (25%)]\tLoss: 0.009688\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.006805\n",
            "Train Epoch: 3 [15680/60000 (26%)]\tLoss: 0.000908\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.063206\n",
            "Train Epoch: 3 [16320/60000 (27%)]\tLoss: 0.001750\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.145685\n",
            "Train Epoch: 3 [16960/60000 (28%)]\tLoss: 0.101322\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.037659\n",
            "Train Epoch: 3 [17600/60000 (29%)]\tLoss: 0.006430\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.004627\n",
            "Train Epoch: 3 [18240/60000 (30%)]\tLoss: 0.000383\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.001926\n",
            "Train Epoch: 3 [18880/60000 (31%)]\tLoss: 0.012398\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.013390\n",
            "Train Epoch: 3 [19520/60000 (33%)]\tLoss: 0.039261\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.007367\n",
            "Train Epoch: 3 [20160/60000 (34%)]\tLoss: 0.044082\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.000457\n",
            "Train Epoch: 3 [20800/60000 (35%)]\tLoss: 0.000482\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.025158\n",
            "Train Epoch: 3 [21440/60000 (36%)]\tLoss: 0.006801\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.000765\n",
            "Train Epoch: 3 [22080/60000 (37%)]\tLoss: 0.016903\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.036133\n",
            "Train Epoch: 3 [22720/60000 (38%)]\tLoss: 0.004921\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.014831\n",
            "Train Epoch: 3 [23360/60000 (39%)]\tLoss: 0.038072\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.000681\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.050800\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.000150\n",
            "Train Epoch: 3 [24640/60000 (41%)]\tLoss: 0.039597\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.012072\n",
            "Train Epoch: 3 [25280/60000 (42%)]\tLoss: 0.001033\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.003742\n",
            "Train Epoch: 3 [25920/60000 (43%)]\tLoss: 0.001632\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.008899\n",
            "Train Epoch: 3 [26560/60000 (44%)]\tLoss: 0.009754\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.073222\n",
            "Train Epoch: 3 [27200/60000 (45%)]\tLoss: 0.009797\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.200437\n",
            "Train Epoch: 3 [27840/60000 (46%)]\tLoss: 0.014306\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.044314\n",
            "Train Epoch: 3 [28480/60000 (47%)]\tLoss: 0.022384\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.089925\n",
            "Train Epoch: 3 [29120/60000 (49%)]\tLoss: 0.096133\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.127696\n",
            "Train Epoch: 3 [29760/60000 (50%)]\tLoss: 0.006260\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.029719\n",
            "Train Epoch: 3 [30400/60000 (51%)]\tLoss: 0.002370\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.063975\n",
            "Train Epoch: 3 [31040/60000 (52%)]\tLoss: 0.013911\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.025395\n",
            "Train Epoch: 3 [31680/60000 (53%)]\tLoss: 0.045046\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.007572\n",
            "Train Epoch: 3 [32320/60000 (54%)]\tLoss: 0.023134\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.001629\n",
            "Train Epoch: 3 [32960/60000 (55%)]\tLoss: 0.002085\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.043837\n",
            "Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.053578\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.010803\n",
            "Train Epoch: 3 [34240/60000 (57%)]\tLoss: 0.003744\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.020820\n",
            "Train Epoch: 3 [34880/60000 (58%)]\tLoss: 0.040049\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.001109\n",
            "Train Epoch: 3 [35520/60000 (59%)]\tLoss: 0.002692\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.005266\n",
            "Train Epoch: 3 [36160/60000 (60%)]\tLoss: 0.013158\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.066351\n",
            "Train Epoch: 3 [36800/60000 (61%)]\tLoss: 0.000315\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.009938\n",
            "Train Epoch: 3 [37440/60000 (62%)]\tLoss: 0.004615\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.000480\n",
            "Train Epoch: 3 [38080/60000 (63%)]\tLoss: 0.165517\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.003060\n",
            "Train Epoch: 3 [38720/60000 (65%)]\tLoss: 0.014995\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.000970\n",
            "Train Epoch: 3 [39360/60000 (66%)]\tLoss: 0.001485\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.000768\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.027000\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.003240\n",
            "Train Epoch: 3 [40640/60000 (68%)]\tLoss: 0.190952\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.015097\n",
            "Train Epoch: 3 [41280/60000 (69%)]\tLoss: 0.007931\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.043017\n",
            "Train Epoch: 3 [41920/60000 (70%)]\tLoss: 0.001889\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.003711\n",
            "Train Epoch: 3 [42560/60000 (71%)]\tLoss: 0.001393\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.022112\n",
            "Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.002309\n",
            "Train Epoch: 3 [43520/60000 (73%)]\tLoss: 0.001858\n",
            "Train Epoch: 3 [43840/60000 (73%)]\tLoss: 0.008279\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.000899\n",
            "Train Epoch: 3 [44480/60000 (74%)]\tLoss: 0.001585\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.007291\n",
            "Train Epoch: 3 [45120/60000 (75%)]\tLoss: 0.005912\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.083728\n",
            "Train Epoch: 3 [45760/60000 (76%)]\tLoss: 0.117459\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.011403\n",
            "Train Epoch: 3 [46400/60000 (77%)]\tLoss: 0.008357\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.113237\n",
            "Train Epoch: 3 [47040/60000 (78%)]\tLoss: 0.127545\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.004330\n",
            "Train Epoch: 3 [47680/60000 (79%)]\tLoss: 0.038486\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.019559\n",
            "Train Epoch: 3 [48320/60000 (81%)]\tLoss: 0.021296\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.002202\n",
            "Train Epoch: 3 [48960/60000 (82%)]\tLoss: 0.036971\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.020033\n",
            "Train Epoch: 3 [49600/60000 (83%)]\tLoss: 0.055400\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.003583\n",
            "Train Epoch: 3 [50240/60000 (84%)]\tLoss: 0.033588\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.133583\n",
            "Train Epoch: 3 [50880/60000 (85%)]\tLoss: 0.141585\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000668\n",
            "Train Epoch: 3 [51520/60000 (86%)]\tLoss: 0.002349\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.154990\n",
            "Train Epoch: 3 [52160/60000 (87%)]\tLoss: 0.019543\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.198951\n",
            "Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.001001\n",
            "Train Epoch: 3 [53120/60000 (89%)]\tLoss: 0.002513\n",
            "Train Epoch: 3 [53440/60000 (89%)]\tLoss: 0.078616\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.001017\n",
            "Train Epoch: 3 [54080/60000 (90%)]\tLoss: 0.059192\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.145571\n",
            "Train Epoch: 3 [54720/60000 (91%)]\tLoss: 0.000379\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.000451\n",
            "Train Epoch: 3 [55360/60000 (92%)]\tLoss: 0.098925\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.034758\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.021995\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.000286\n",
            "Train Epoch: 3 [56640/60000 (94%)]\tLoss: 0.020563\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.002884\n",
            "Train Epoch: 3 [57280/60000 (95%)]\tLoss: 0.204658\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.119715\n",
            "Train Epoch: 3 [57920/60000 (97%)]\tLoss: 0.012895\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.007357\n",
            "Train Epoch: 3 [58560/60000 (98%)]\tLoss: 0.002180\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.005931\n",
            "Train Epoch: 3 [59200/60000 (99%)]\tLoss: 0.001849\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.002685\n",
            "Train Epoch: 3 [59840/60000 (100%)]\tLoss: 0.003139\n",
            "\n",
            "Test set: Average loss: 0.0321, Accuracy: 9897/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000254\n",
            "Train Epoch: 4 [320/60000 (1%)]\tLoss: 0.003769\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.001351\n",
            "Train Epoch: 4 [960/60000 (2%)]\tLoss: 0.001369\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.002440\n",
            "Train Epoch: 4 [1600/60000 (3%)]\tLoss: 0.039528\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.002143\n",
            "Train Epoch: 4 [2240/60000 (4%)]\tLoss: 0.023510\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.006184\n",
            "Train Epoch: 4 [2880/60000 (5%)]\tLoss: 0.003394\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.002668\n",
            "Train Epoch: 4 [3520/60000 (6%)]\tLoss: 0.009076\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.024663\n",
            "Train Epoch: 4 [4160/60000 (7%)]\tLoss: 0.070803\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.017593\n",
            "Train Epoch: 4 [4800/60000 (8%)]\tLoss: 0.031688\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.133410\n",
            "Train Epoch: 4 [5440/60000 (9%)]\tLoss: 0.001320\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.192579\n",
            "Train Epoch: 4 [6080/60000 (10%)]\tLoss: 0.031332\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.080256\n",
            "Train Epoch: 4 [6720/60000 (11%)]\tLoss: 0.025902\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.048646\n",
            "Train Epoch: 4 [7360/60000 (12%)]\tLoss: 0.001156\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.011790\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.227397\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.084233\n",
            "Train Epoch: 4 [8640/60000 (14%)]\tLoss: 0.051905\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.021723\n",
            "Train Epoch: 4 [9280/60000 (15%)]\tLoss: 0.000215\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.000802\n",
            "Train Epoch: 4 [9920/60000 (17%)]\tLoss: 0.005519\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.000439\n",
            "Train Epoch: 4 [10560/60000 (18%)]\tLoss: 0.000169\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.029312\n",
            "Train Epoch: 4 [11200/60000 (19%)]\tLoss: 0.021036\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.054884\n",
            "Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.091418\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.004529\n",
            "Train Epoch: 4 [12480/60000 (21%)]\tLoss: 0.031367\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.018255\n",
            "Train Epoch: 4 [13120/60000 (22%)]\tLoss: 0.001058\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.001386\n",
            "Train Epoch: 4 [13760/60000 (23%)]\tLoss: 0.012975\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.121447\n",
            "Train Epoch: 4 [14400/60000 (24%)]\tLoss: 0.000630\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.001029\n",
            "Train Epoch: 4 [15040/60000 (25%)]\tLoss: 0.001699\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.395899\n",
            "Train Epoch: 4 [15680/60000 (26%)]\tLoss: 0.002486\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.016333\n",
            "Train Epoch: 4 [16320/60000 (27%)]\tLoss: 0.008444\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.002999\n",
            "Train Epoch: 4 [16960/60000 (28%)]\tLoss: 0.009689\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.008065\n",
            "Train Epoch: 4 [17600/60000 (29%)]\tLoss: 0.012464\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.001869\n",
            "Train Epoch: 4 [18240/60000 (30%)]\tLoss: 0.012477\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.004792\n",
            "Train Epoch: 4 [18880/60000 (31%)]\tLoss: 0.002623\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.063136\n",
            "Train Epoch: 4 [19520/60000 (33%)]\tLoss: 0.016130\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.015876\n",
            "Train Epoch: 4 [20160/60000 (34%)]\tLoss: 0.000095\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.002311\n",
            "Train Epoch: 4 [20800/60000 (35%)]\tLoss: 0.065428\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.278461\n",
            "Train Epoch: 4 [21440/60000 (36%)]\tLoss: 0.314077\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.009882\n",
            "Train Epoch: 4 [22080/60000 (37%)]\tLoss: 0.050331\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.028431\n",
            "Train Epoch: 4 [22720/60000 (38%)]\tLoss: 0.028718\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.000586\n",
            "Train Epoch: 4 [23360/60000 (39%)]\tLoss: 0.001964\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.026084\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.013322\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.000533\n",
            "Train Epoch: 4 [24640/60000 (41%)]\tLoss: 0.002247\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.001503\n",
            "Train Epoch: 4 [25280/60000 (42%)]\tLoss: 0.037549\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.048378\n",
            "Train Epoch: 4 [25920/60000 (43%)]\tLoss: 0.000934\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.000111\n",
            "Train Epoch: 4 [26560/60000 (44%)]\tLoss: 0.056139\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.034359\n",
            "Train Epoch: 4 [27200/60000 (45%)]\tLoss: 0.001196\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.077864\n",
            "Train Epoch: 4 [27840/60000 (46%)]\tLoss: 0.005823\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.014596\n",
            "Train Epoch: 4 [28480/60000 (47%)]\tLoss: 0.000623\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.118266\n",
            "Train Epoch: 4 [29120/60000 (49%)]\tLoss: 0.016851\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.184842\n",
            "Train Epoch: 4 [29760/60000 (50%)]\tLoss: 0.023393\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.002339\n",
            "Train Epoch: 4 [30400/60000 (51%)]\tLoss: 0.022088\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.000745\n",
            "Train Epoch: 4 [31040/60000 (52%)]\tLoss: 0.000452\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.003171\n",
            "Train Epoch: 4 [31680/60000 (53%)]\tLoss: 0.377219\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.098363\n",
            "Train Epoch: 4 [32320/60000 (54%)]\tLoss: 0.013809\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.033911\n",
            "Train Epoch: 4 [32960/60000 (55%)]\tLoss: 0.101677\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.026490\n",
            "Train Epoch: 4 [33600/60000 (56%)]\tLoss: 0.044845\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.002254\n",
            "Train Epoch: 4 [34240/60000 (57%)]\tLoss: 0.011185\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.004516\n",
            "Train Epoch: 4 [34880/60000 (58%)]\tLoss: 0.011048\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.012326\n",
            "Train Epoch: 4 [35520/60000 (59%)]\tLoss: 0.002333\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.003190\n",
            "Train Epoch: 4 [36160/60000 (60%)]\tLoss: 0.001031\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.003943\n",
            "Train Epoch: 4 [36800/60000 (61%)]\tLoss: 0.000551\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.012489\n",
            "Train Epoch: 4 [37440/60000 (62%)]\tLoss: 0.002549\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.004888\n",
            "Train Epoch: 4 [38080/60000 (63%)]\tLoss: 0.000144\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.001871\n",
            "Train Epoch: 4 [38720/60000 (65%)]\tLoss: 0.054728\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.029877\n",
            "Train Epoch: 4 [39360/60000 (66%)]\tLoss: 0.011339\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.003340\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.000437\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.000252\n",
            "Train Epoch: 4 [40640/60000 (68%)]\tLoss: 0.104688\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.004567\n",
            "Train Epoch: 4 [41280/60000 (69%)]\tLoss: 0.020493\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.203261\n",
            "Train Epoch: 4 [41920/60000 (70%)]\tLoss: 0.003985\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.000984\n",
            "Train Epoch: 4 [42560/60000 (71%)]\tLoss: 0.000379\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.012462\n",
            "Train Epoch: 4 [43200/60000 (72%)]\tLoss: 0.012341\n",
            "Train Epoch: 4 [43520/60000 (73%)]\tLoss: 0.001103\n",
            "Train Epoch: 4 [43840/60000 (73%)]\tLoss: 0.007748\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.012053\n",
            "Train Epoch: 4 [44480/60000 (74%)]\tLoss: 0.000921\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.003235\n",
            "Train Epoch: 4 [45120/60000 (75%)]\tLoss: 0.043183\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.017974\n",
            "Train Epoch: 4 [45760/60000 (76%)]\tLoss: 0.005260\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.005989\n",
            "Train Epoch: 4 [46400/60000 (77%)]\tLoss: 0.056695\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.023846\n",
            "Train Epoch: 4 [47040/60000 (78%)]\tLoss: 0.000151\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.067541\n",
            "Train Epoch: 4 [47680/60000 (79%)]\tLoss: 0.041001\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.000846\n",
            "Train Epoch: 4 [48320/60000 (81%)]\tLoss: 0.002239\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.000412\n",
            "Train Epoch: 4 [48960/60000 (82%)]\tLoss: 0.000209\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [49600/60000 (83%)]\tLoss: 0.003058\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.009361\n",
            "Train Epoch: 4 [50240/60000 (84%)]\tLoss: 0.010304\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.093134\n",
            "Train Epoch: 4 [50880/60000 (85%)]\tLoss: 0.003116\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.129614\n",
            "Train Epoch: 4 [51520/60000 (86%)]\tLoss: 0.006128\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.010987\n",
            "Train Epoch: 4 [52160/60000 (87%)]\tLoss: 0.003399\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.014245\n",
            "Train Epoch: 4 [52800/60000 (88%)]\tLoss: 0.052296\n",
            "Train Epoch: 4 [53120/60000 (89%)]\tLoss: 0.001674\n",
            "Train Epoch: 4 [53440/60000 (89%)]\tLoss: 0.000676\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.000880\n",
            "Train Epoch: 4 [54080/60000 (90%)]\tLoss: 0.083357\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.047211\n",
            "Train Epoch: 4 [54720/60000 (91%)]\tLoss: 0.003681\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.021898\n",
            "Train Epoch: 4 [55360/60000 (92%)]\tLoss: 0.007540\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.006494\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.079705\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.127852\n",
            "Train Epoch: 4 [56640/60000 (94%)]\tLoss: 0.000808\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.015982\n",
            "Train Epoch: 4 [57280/60000 (95%)]\tLoss: 0.000072\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.023266\n",
            "Train Epoch: 4 [57920/60000 (97%)]\tLoss: 0.010815\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.042589\n",
            "Train Epoch: 4 [58560/60000 (98%)]\tLoss: 0.091471\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.000618\n",
            "Train Epoch: 4 [59200/60000 (99%)]\tLoss: 0.000057\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.032402\n",
            "Train Epoch: 4 [59840/60000 (100%)]\tLoss: 0.000110\n",
            "\n",
            "Test set: Average loss: 0.0262, Accuracy: 9914/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.002273\n",
            "Train Epoch: 5 [320/60000 (1%)]\tLoss: 0.000684\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.011237\n",
            "Train Epoch: 5 [960/60000 (2%)]\tLoss: 0.008321\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.066570\n",
            "Train Epoch: 5 [1600/60000 (3%)]\tLoss: 0.000807\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.000815\n",
            "Train Epoch: 5 [2240/60000 (4%)]\tLoss: 0.000038\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.000487\n",
            "Train Epoch: 5 [2880/60000 (5%)]\tLoss: 0.015580\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.001330\n",
            "Train Epoch: 5 [3520/60000 (6%)]\tLoss: 0.001348\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.021643\n",
            "Train Epoch: 5 [4160/60000 (7%)]\tLoss: 0.000213\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.002976\n",
            "Train Epoch: 5 [4800/60000 (8%)]\tLoss: 0.001185\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.000735\n",
            "Train Epoch: 5 [5440/60000 (9%)]\tLoss: 0.000977\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.006487\n",
            "Train Epoch: 5 [6080/60000 (10%)]\tLoss: 0.129364\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.002537\n",
            "Train Epoch: 5 [6720/60000 (11%)]\tLoss: 0.010931\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.004105\n",
            "Train Epoch: 5 [7360/60000 (12%)]\tLoss: 0.000855\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.042874\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.001738\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.002237\n",
            "Train Epoch: 5 [8640/60000 (14%)]\tLoss: 0.007708\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.003025\n",
            "Train Epoch: 5 [9280/60000 (15%)]\tLoss: 0.217279\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.002925\n",
            "Train Epoch: 5 [9920/60000 (17%)]\tLoss: 0.006050\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.001221\n",
            "Train Epoch: 5 [10560/60000 (18%)]\tLoss: 0.000085\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.005768\n",
            "Train Epoch: 5 [11200/60000 (19%)]\tLoss: 0.004634\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.014363\n",
            "Train Epoch: 5 [11840/60000 (20%)]\tLoss: 0.025304\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.021643\n",
            "Train Epoch: 5 [12480/60000 (21%)]\tLoss: 0.004130\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000434\n",
            "Train Epoch: 5 [13120/60000 (22%)]\tLoss: 0.001315\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.026641\n",
            "Train Epoch: 5 [13760/60000 (23%)]\tLoss: 0.000192\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.000354\n",
            "Train Epoch: 5 [14400/60000 (24%)]\tLoss: 0.085321\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.009026\n",
            "Train Epoch: 5 [15040/60000 (25%)]\tLoss: 0.000071\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.001731\n",
            "Train Epoch: 5 [15680/60000 (26%)]\tLoss: 0.073751\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.000915\n",
            "Train Epoch: 5 [16320/60000 (27%)]\tLoss: 0.010119\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.016022\n",
            "Train Epoch: 5 [16960/60000 (28%)]\tLoss: 0.008811\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.026311\n",
            "Train Epoch: 5 [17600/60000 (29%)]\tLoss: 0.013938\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.013996\n",
            "Train Epoch: 5 [18240/60000 (30%)]\tLoss: 0.022092\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.059682\n",
            "Train Epoch: 5 [18880/60000 (31%)]\tLoss: 0.031690\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000238\n",
            "Train Epoch: 5 [19520/60000 (33%)]\tLoss: 0.003410\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.000040\n",
            "Train Epoch: 5 [20160/60000 (34%)]\tLoss: 0.000112\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.000809\n",
            "Train Epoch: 5 [20800/60000 (35%)]\tLoss: 0.013157\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.000117\n",
            "Train Epoch: 5 [21440/60000 (36%)]\tLoss: 0.003654\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.000219\n",
            "Train Epoch: 5 [22080/60000 (37%)]\tLoss: 0.004105\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.022840\n",
            "Train Epoch: 5 [22720/60000 (38%)]\tLoss: 0.001972\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.026942\n",
            "Train Epoch: 5 [23360/60000 (39%)]\tLoss: 0.000299\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.026295\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.013010\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.000312\n",
            "Train Epoch: 5 [24640/60000 (41%)]\tLoss: 0.004470\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.006642\n",
            "Train Epoch: 5 [25280/60000 (42%)]\tLoss: 0.002342\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.003007\n",
            "Train Epoch: 5 [25920/60000 (43%)]\tLoss: 0.000586\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.000869\n",
            "Train Epoch: 5 [26560/60000 (44%)]\tLoss: 0.044255\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.020950\n",
            "Train Epoch: 5 [27200/60000 (45%)]\tLoss: 0.001581\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.001948\n",
            "Train Epoch: 5 [27840/60000 (46%)]\tLoss: 0.084834\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.002022\n",
            "Train Epoch: 5 [28480/60000 (47%)]\tLoss: 0.002093\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.002022\n",
            "Train Epoch: 5 [29120/60000 (49%)]\tLoss: 0.011102\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.010164\n",
            "Train Epoch: 5 [29760/60000 (50%)]\tLoss: 0.000148\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.004521\n",
            "Train Epoch: 5 [30400/60000 (51%)]\tLoss: 0.003083\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.025193\n",
            "Train Epoch: 5 [31040/60000 (52%)]\tLoss: 0.062760\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.055932\n",
            "Train Epoch: 5 [31680/60000 (53%)]\tLoss: 0.005222\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.028628\n",
            "Train Epoch: 5 [32320/60000 (54%)]\tLoss: 0.000700\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.000035\n",
            "Train Epoch: 5 [32960/60000 (55%)]\tLoss: 0.100718\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.027924\n",
            "Train Epoch: 5 [33600/60000 (56%)]\tLoss: 0.001756\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.005645\n",
            "Train Epoch: 5 [34240/60000 (57%)]\tLoss: 0.046630\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.002814\n",
            "Train Epoch: 5 [34880/60000 (58%)]\tLoss: 0.000202\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.006002\n",
            "Train Epoch: 5 [35520/60000 (59%)]\tLoss: 0.017263\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.012730\n",
            "Train Epoch: 5 [36160/60000 (60%)]\tLoss: 0.105905\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.004649\n",
            "Train Epoch: 5 [36800/60000 (61%)]\tLoss: 0.047416\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.000421\n",
            "Train Epoch: 5 [37440/60000 (62%)]\tLoss: 0.005537\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.000297\n",
            "Train Epoch: 5 [38080/60000 (63%)]\tLoss: 0.000135\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.001816\n",
            "Train Epoch: 5 [38720/60000 (65%)]\tLoss: 0.002729\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.002716\n",
            "Train Epoch: 5 [39360/60000 (66%)]\tLoss: 0.003512\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.013729\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.000130\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.033643\n",
            "Train Epoch: 5 [40640/60000 (68%)]\tLoss: 0.004960\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.029176\n",
            "Train Epoch: 5 [41280/60000 (69%)]\tLoss: 0.001956\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.004374\n",
            "Train Epoch: 5 [41920/60000 (70%)]\tLoss: 0.000406\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.000269\n",
            "Train Epoch: 5 [42560/60000 (71%)]\tLoss: 0.028747\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.014113\n",
            "Train Epoch: 5 [43200/60000 (72%)]\tLoss: 0.017793\n",
            "Train Epoch: 5 [43520/60000 (73%)]\tLoss: 0.000506\n",
            "Train Epoch: 5 [43840/60000 (73%)]\tLoss: 0.002328\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.009605\n",
            "Train Epoch: 5 [44480/60000 (74%)]\tLoss: 0.000233\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000560\n",
            "Train Epoch: 5 [45120/60000 (75%)]\tLoss: 0.102659\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.018181\n",
            "Train Epoch: 5 [45760/60000 (76%)]\tLoss: 0.032194\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.003700\n",
            "Train Epoch: 5 [46400/60000 (77%)]\tLoss: 0.000297\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.001251\n",
            "Train Epoch: 5 [47040/60000 (78%)]\tLoss: 0.105416\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.019264\n",
            "Train Epoch: 5 [47680/60000 (79%)]\tLoss: 0.000064\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.001529\n",
            "Train Epoch: 5 [48320/60000 (81%)]\tLoss: 0.005134\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.039868\n",
            "Train Epoch: 5 [48960/60000 (82%)]\tLoss: 0.004686\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.001340\n",
            "Train Epoch: 5 [49600/60000 (83%)]\tLoss: 0.005280\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.000466\n",
            "Train Epoch: 5 [50240/60000 (84%)]\tLoss: 0.000514\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.023585\n",
            "Train Epoch: 5 [50880/60000 (85%)]\tLoss: 0.000730\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001269\n",
            "Train Epoch: 5 [51520/60000 (86%)]\tLoss: 0.000064\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.006943\n",
            "Train Epoch: 5 [52160/60000 (87%)]\tLoss: 0.004182\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.002963\n",
            "Train Epoch: 5 [52800/60000 (88%)]\tLoss: 0.000446\n",
            "Train Epoch: 5 [53120/60000 (89%)]\tLoss: 0.000061\n",
            "Train Epoch: 5 [53440/60000 (89%)]\tLoss: 0.000664\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.061880\n",
            "Train Epoch: 5 [54080/60000 (90%)]\tLoss: 0.007943\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.004722\n",
            "Train Epoch: 5 [54720/60000 (91%)]\tLoss: 0.016200\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.001057\n",
            "Train Epoch: 5 [55360/60000 (92%)]\tLoss: 0.004489\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.000580\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.036177\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.125491\n",
            "Train Epoch: 5 [56640/60000 (94%)]\tLoss: 0.008437\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.000671\n",
            "Train Epoch: 5 [57280/60000 (95%)]\tLoss: 0.000192\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.005918\n",
            "Train Epoch: 5 [57920/60000 (97%)]\tLoss: 0.016739\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.075792\n",
            "Train Epoch: 5 [58560/60000 (98%)]\tLoss: 0.025981\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.002573\n",
            "Train Epoch: 5 [59200/60000 (99%)]\tLoss: 0.007542\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.062485\n",
            "Train Epoch: 5 [59840/60000 (100%)]\tLoss: 0.000041\n",
            "\n",
            "Test set: Average loss: 0.0322, Accuracy: 9906/10000 (99%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.032370\n",
            "Train Epoch: 6 [320/60000 (1%)]\tLoss: 0.000145\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.007195\n",
            "Train Epoch: 6 [960/60000 (2%)]\tLoss: 0.004956\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.005865\n",
            "Train Epoch: 6 [1600/60000 (3%)]\tLoss: 0.017297\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.001156\n",
            "Train Epoch: 6 [2240/60000 (4%)]\tLoss: 0.001115\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.003902\n",
            "Train Epoch: 6 [2880/60000 (5%)]\tLoss: 0.003905\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.001607\n",
            "Train Epoch: 6 [3520/60000 (6%)]\tLoss: 0.003949\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.000016\n",
            "Train Epoch: 6 [4160/60000 (7%)]\tLoss: 0.168496\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.008194\n",
            "Train Epoch: 6 [4800/60000 (8%)]\tLoss: 0.036844\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.003979\n",
            "Train Epoch: 6 [5440/60000 (9%)]\tLoss: 0.000006\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.000008\n",
            "Train Epoch: 6 [6080/60000 (10%)]\tLoss: 0.000791\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000047\n",
            "Train Epoch: 6 [6720/60000 (11%)]\tLoss: 0.000027\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.025796\n",
            "Train Epoch: 6 [7360/60000 (12%)]\tLoss: 0.005137\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.001167\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.042542\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.001689\n",
            "Train Epoch: 6 [8640/60000 (14%)]\tLoss: 0.000456\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.027124\n",
            "Train Epoch: 6 [9280/60000 (15%)]\tLoss: 0.005511\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.000220\n",
            "Train Epoch: 6 [9920/60000 (17%)]\tLoss: 0.004415\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.008300\n",
            "Train Epoch: 6 [10560/60000 (18%)]\tLoss: 0.110259\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.003836\n",
            "Train Epoch: 6 [11200/60000 (19%)]\tLoss: 0.003329\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.055421\n",
            "Train Epoch: 6 [11840/60000 (20%)]\tLoss: 0.012894\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.001030\n",
            "Train Epoch: 6 [12480/60000 (21%)]\tLoss: 0.020619\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000743\n",
            "Train Epoch: 6 [13120/60000 (22%)]\tLoss: 0.000240\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.071102\n",
            "Train Epoch: 6 [13760/60000 (23%)]\tLoss: 0.001268\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.012367\n",
            "Train Epoch: 6 [14400/60000 (24%)]\tLoss: 0.000234\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.034306\n",
            "Train Epoch: 6 [15040/60000 (25%)]\tLoss: 0.002942\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.001424\n",
            "Train Epoch: 6 [15680/60000 (26%)]\tLoss: 0.013336\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.008224\n",
            "Train Epoch: 6 [16320/60000 (27%)]\tLoss: 0.013637\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.000199\n",
            "Train Epoch: 6 [16960/60000 (28%)]\tLoss: 0.000016\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.000251\n",
            "Train Epoch: 6 [17600/60000 (29%)]\tLoss: 0.000661\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.003009\n",
            "Train Epoch: 6 [18240/60000 (30%)]\tLoss: 0.000157\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.001391\n",
            "Train Epoch: 6 [18880/60000 (31%)]\tLoss: 0.000171\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.002117\n",
            "Train Epoch: 6 [19520/60000 (33%)]\tLoss: 0.003181\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.003956\n",
            "Train Epoch: 6 [20160/60000 (34%)]\tLoss: 0.019950\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.000268\n",
            "Train Epoch: 6 [20800/60000 (35%)]\tLoss: 0.000460\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.001722\n",
            "Train Epoch: 6 [21440/60000 (36%)]\tLoss: 0.001654\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.000085\n",
            "Train Epoch: 6 [22080/60000 (37%)]\tLoss: 0.000700\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.092099\n",
            "Train Epoch: 6 [22720/60000 (38%)]\tLoss: 0.001047\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.003476\n",
            "Train Epoch: 6 [23360/60000 (39%)]\tLoss: 0.011205\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.000937\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.003722\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.000690\n",
            "Train Epoch: 6 [24640/60000 (41%)]\tLoss: 0.001515\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.000633\n",
            "Train Epoch: 6 [25280/60000 (42%)]\tLoss: 0.000187\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.066849\n",
            "Train Epoch: 6 [25920/60000 (43%)]\tLoss: 0.004949\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.001823\n",
            "Train Epoch: 6 [26560/60000 (44%)]\tLoss: 0.001417\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.000476\n",
            "Train Epoch: 6 [27200/60000 (45%)]\tLoss: 0.000756\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.000886\n",
            "Train Epoch: 6 [27840/60000 (46%)]\tLoss: 0.001798\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.031962\n",
            "Train Epoch: 6 [28480/60000 (47%)]\tLoss: 0.006321\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.000863\n",
            "Train Epoch: 6 [29120/60000 (49%)]\tLoss: 0.002383\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.000030\n",
            "Train Epoch: 6 [29760/60000 (50%)]\tLoss: 0.000387\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.011179\n",
            "Train Epoch: 6 [30400/60000 (51%)]\tLoss: 0.014431\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.014423\n",
            "Train Epoch: 6 [31040/60000 (52%)]\tLoss: 0.002590\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.003898\n",
            "Train Epoch: 6 [31680/60000 (53%)]\tLoss: 0.000053\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000675\n",
            "Train Epoch: 6 [32320/60000 (54%)]\tLoss: 0.000473\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.000320\n",
            "Train Epoch: 6 [32960/60000 (55%)]\tLoss: 0.180112\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.000133\n",
            "Train Epoch: 6 [33600/60000 (56%)]\tLoss: 0.006983\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.001838\n",
            "Train Epoch: 6 [34240/60000 (57%)]\tLoss: 0.000775\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.007411\n",
            "Train Epoch: 6 [34880/60000 (58%)]\tLoss: 0.002247\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.003243\n",
            "Train Epoch: 6 [35520/60000 (59%)]\tLoss: 0.002330\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.002002\n",
            "Train Epoch: 6 [36160/60000 (60%)]\tLoss: 0.000426\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.001808\n",
            "Train Epoch: 6 [36800/60000 (61%)]\tLoss: 0.000527\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.002510\n",
            "Train Epoch: 6 [37440/60000 (62%)]\tLoss: 0.023933\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.049866\n",
            "Train Epoch: 6 [38080/60000 (63%)]\tLoss: 0.000381\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001031\n",
            "Train Epoch: 6 [38720/60000 (65%)]\tLoss: 0.010668\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.007740\n",
            "Train Epoch: 6 [39360/60000 (66%)]\tLoss: 0.003866\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.000080\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.005098\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.026024\n",
            "Train Epoch: 6 [40640/60000 (68%)]\tLoss: 0.040191\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.002878\n",
            "Train Epoch: 6 [41280/60000 (69%)]\tLoss: 0.022641\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.000832\n",
            "Train Epoch: 6 [41920/60000 (70%)]\tLoss: 0.015238\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.033033\n",
            "Train Epoch: 6 [42560/60000 (71%)]\tLoss: 0.002211\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.000067\n",
            "Train Epoch: 6 [43200/60000 (72%)]\tLoss: 0.000961\n",
            "Train Epoch: 6 [43520/60000 (73%)]\tLoss: 0.000246\n",
            "Train Epoch: 6 [43840/60000 (73%)]\tLoss: 0.010466\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.000230\n",
            "Train Epoch: 6 [44480/60000 (74%)]\tLoss: 0.000114\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.031232\n",
            "Train Epoch: 6 [45120/60000 (75%)]\tLoss: 0.000045\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.090465\n",
            "Train Epoch: 6 [45760/60000 (76%)]\tLoss: 0.001978\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.034245\n",
            "Train Epoch: 6 [46400/60000 (77%)]\tLoss: 0.031702\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.110812\n",
            "Train Epoch: 6 [47040/60000 (78%)]\tLoss: 0.000184\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.000154\n",
            "Train Epoch: 6 [47680/60000 (79%)]\tLoss: 0.003603\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.018350\n",
            "Train Epoch: 6 [48320/60000 (81%)]\tLoss: 0.002324\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.006432\n",
            "Train Epoch: 6 [48960/60000 (82%)]\tLoss: 0.003149\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.012089\n",
            "Train Epoch: 6 [49600/60000 (83%)]\tLoss: 0.003360\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.000476\n",
            "Train Epoch: 6 [50240/60000 (84%)]\tLoss: 0.074006\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.000393\n",
            "Train Epoch: 6 [50880/60000 (85%)]\tLoss: 0.000162\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000243\n",
            "Train Epoch: 6 [51520/60000 (86%)]\tLoss: 0.014117\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.000608\n",
            "Train Epoch: 6 [52160/60000 (87%)]\tLoss: 0.000169\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.043917\n",
            "Train Epoch: 6 [52800/60000 (88%)]\tLoss: 0.001113\n",
            "Train Epoch: 6 [53120/60000 (89%)]\tLoss: 0.000390\n",
            "Train Epoch: 6 [53440/60000 (89%)]\tLoss: 0.099861\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.002814\n",
            "Train Epoch: 6 [54080/60000 (90%)]\tLoss: 0.000442\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.000631\n",
            "Train Epoch: 6 [54720/60000 (91%)]\tLoss: 0.000753\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.000323\n",
            "Train Epoch: 6 [55360/60000 (92%)]\tLoss: 0.001019\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.009226\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.000962\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.002050\n",
            "Train Epoch: 6 [56640/60000 (94%)]\tLoss: 0.007843\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.000124\n",
            "Train Epoch: 6 [57280/60000 (95%)]\tLoss: 0.008217\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000187\n",
            "Train Epoch: 6 [57920/60000 (97%)]\tLoss: 0.013397\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.035333\n",
            "Train Epoch: 6 [58560/60000 (98%)]\tLoss: 0.000164\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.015506\n",
            "Train Epoch: 6 [59200/60000 (99%)]\tLoss: 0.011849\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.025061\n",
            "Train Epoch: 6 [59840/60000 (100%)]\tLoss: 0.000435\n",
            "\n",
            "Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000206\n",
            "Train Epoch: 7 [320/60000 (1%)]\tLoss: 0.013152\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.000023\n",
            "Train Epoch: 7 [960/60000 (2%)]\tLoss: 0.000468\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.002054\n",
            "Train Epoch: 7 [1600/60000 (3%)]\tLoss: 0.001370\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.002764\n",
            "Train Epoch: 7 [2240/60000 (4%)]\tLoss: 0.001350\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.004611\n",
            "Train Epoch: 7 [2880/60000 (5%)]\tLoss: 0.000489\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.015223\n",
            "Train Epoch: 7 [3520/60000 (6%)]\tLoss: 0.001571\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.001636\n",
            "Train Epoch: 7 [4160/60000 (7%)]\tLoss: 0.004723\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.044536\n",
            "Train Epoch: 7 [4800/60000 (8%)]\tLoss: 0.000564\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.000022\n",
            "Train Epoch: 7 [5440/60000 (9%)]\tLoss: 0.007874\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.006251\n",
            "Train Epoch: 7 [6080/60000 (10%)]\tLoss: 0.001879\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000905\n",
            "Train Epoch: 7 [6720/60000 (11%)]\tLoss: 0.006588\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.000125\n",
            "Train Epoch: 7 [7360/60000 (12%)]\tLoss: 0.000391\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.000616\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.000247\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.000172\n",
            "Train Epoch: 7 [8640/60000 (14%)]\tLoss: 0.009926\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.000234\n",
            "Train Epoch: 7 [9280/60000 (15%)]\tLoss: 0.031399\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.011774\n",
            "Train Epoch: 7 [9920/60000 (17%)]\tLoss: 0.065409\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.001852\n",
            "Train Epoch: 7 [10560/60000 (18%)]\tLoss: 0.010479\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.000011\n",
            "Train Epoch: 7 [11200/60000 (19%)]\tLoss: 0.005620\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.000033\n",
            "Train Epoch: 7 [11840/60000 (20%)]\tLoss: 0.000190\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.003600\n",
            "Train Epoch: 7 [12480/60000 (21%)]\tLoss: 0.002844\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003270\n",
            "Train Epoch: 7 [13120/60000 (22%)]\tLoss: 0.000471\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.000582\n",
            "Train Epoch: 7 [13760/60000 (23%)]\tLoss: 0.002246\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.000446\n",
            "Train Epoch: 7 [14400/60000 (24%)]\tLoss: 0.000111\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.000960\n",
            "Train Epoch: 7 [15040/60000 (25%)]\tLoss: 0.000047\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.039270\n",
            "Train Epoch: 7 [15680/60000 (26%)]\tLoss: 0.003783\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000204\n",
            "Train Epoch: 7 [16320/60000 (27%)]\tLoss: 0.021322\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.022797\n",
            "Train Epoch: 7 [16960/60000 (28%)]\tLoss: 0.010270\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.000003\n",
            "Train Epoch: 7 [17600/60000 (29%)]\tLoss: 0.000488\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.000004\n",
            "Train Epoch: 7 [18240/60000 (30%)]\tLoss: 0.002191\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.000105\n",
            "Train Epoch: 7 [18880/60000 (31%)]\tLoss: 0.000242\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.002329\n",
            "Train Epoch: 7 [19520/60000 (33%)]\tLoss: 0.006108\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.000335\n",
            "Train Epoch: 7 [20160/60000 (34%)]\tLoss: 0.000271\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.000038\n",
            "Train Epoch: 7 [20800/60000 (35%)]\tLoss: 0.005943\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.000095\n",
            "Train Epoch: 7 [21440/60000 (36%)]\tLoss: 0.000384\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.002874\n",
            "Train Epoch: 7 [22080/60000 (37%)]\tLoss: 0.003438\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.001303\n",
            "Train Epoch: 7 [22720/60000 (38%)]\tLoss: 0.000146\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.006740\n",
            "Train Epoch: 7 [23360/60000 (39%)]\tLoss: 0.000413\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.000801\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.000001\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.000009\n",
            "Train Epoch: 7 [24640/60000 (41%)]\tLoss: 0.000047\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.003029\n",
            "Train Epoch: 7 [25280/60000 (42%)]\tLoss: 0.001693\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000140\n",
            "Train Epoch: 7 [25920/60000 (43%)]\tLoss: 0.019460\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.000211\n",
            "Train Epoch: 7 [26560/60000 (44%)]\tLoss: 0.000009\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.062088\n",
            "Train Epoch: 7 [27200/60000 (45%)]\tLoss: 0.000012\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.004161\n",
            "Train Epoch: 7 [27840/60000 (46%)]\tLoss: 0.002311\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.000047\n",
            "Train Epoch: 7 [28480/60000 (47%)]\tLoss: 0.000327\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.002187\n",
            "Train Epoch: 7 [29120/60000 (49%)]\tLoss: 0.002891\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.010318\n",
            "Train Epoch: 7 [29760/60000 (50%)]\tLoss: 0.000194\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.035755\n",
            "Train Epoch: 7 [30400/60000 (51%)]\tLoss: 0.034622\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.000475\n",
            "Train Epoch: 7 [31040/60000 (52%)]\tLoss: 0.000035\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.000009\n",
            "Train Epoch: 7 [31680/60000 (53%)]\tLoss: 0.010028\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001967\n",
            "Train Epoch: 7 [32320/60000 (54%)]\tLoss: 0.000009\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.001031\n",
            "Train Epoch: 7 [32960/60000 (55%)]\tLoss: 0.000140\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.000235\n",
            "Train Epoch: 7 [33600/60000 (56%)]\tLoss: 0.000352\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.016375\n",
            "Train Epoch: 7 [34240/60000 (57%)]\tLoss: 0.002202\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.000012\n",
            "Train Epoch: 7 [34880/60000 (58%)]\tLoss: 0.000919\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.000776\n",
            "Train Epoch: 7 [35520/60000 (59%)]\tLoss: 0.000041\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.039247\n",
            "Train Epoch: 7 [36160/60000 (60%)]\tLoss: 0.001749\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.076916\n",
            "Train Epoch: 7 [36800/60000 (61%)]\tLoss: 0.008990\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.028612\n",
            "Train Epoch: 7 [37440/60000 (62%)]\tLoss: 0.008043\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.011675\n",
            "Train Epoch: 7 [38080/60000 (63%)]\tLoss: 0.001970\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000060\n",
            "Train Epoch: 7 [38720/60000 (65%)]\tLoss: 0.005214\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.000962\n",
            "Train Epoch: 7 [39360/60000 (66%)]\tLoss: 0.045983\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.002079\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.117403\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.002118\n",
            "Train Epoch: 7 [40640/60000 (68%)]\tLoss: 0.000088\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.002251\n",
            "Train Epoch: 7 [41280/60000 (69%)]\tLoss: 0.005358\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.105406\n",
            "Train Epoch: 7 [41920/60000 (70%)]\tLoss: 0.100935\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.000573\n",
            "Train Epoch: 7 [42560/60000 (71%)]\tLoss: 0.193552\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.010374\n",
            "Train Epoch: 7 [43200/60000 (72%)]\tLoss: 0.163051\n",
            "Train Epoch: 7 [43520/60000 (73%)]\tLoss: 0.001906\n",
            "Train Epoch: 7 [43840/60000 (73%)]\tLoss: 0.000518\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.000396\n",
            "Train Epoch: 7 [44480/60000 (74%)]\tLoss: 0.001609\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.001014\n",
            "Train Epoch: 7 [45120/60000 (75%)]\tLoss: 0.000415\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.016561\n",
            "Train Epoch: 7 [45760/60000 (76%)]\tLoss: 0.100802\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.003278\n",
            "Train Epoch: 7 [46400/60000 (77%)]\tLoss: 0.000184\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.000098\n",
            "Train Epoch: 7 [47040/60000 (78%)]\tLoss: 0.012335\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.023888\n",
            "Train Epoch: 7 [47680/60000 (79%)]\tLoss: 0.001351\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.000727\n",
            "Train Epoch: 7 [48320/60000 (81%)]\tLoss: 0.037155\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.002667\n",
            "Train Epoch: 7 [48960/60000 (82%)]\tLoss: 0.007613\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.000979\n",
            "Train Epoch: 7 [49600/60000 (83%)]\tLoss: 0.002378\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.005639\n",
            "Train Epoch: 7 [50240/60000 (84%)]\tLoss: 0.002376\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.001233\n",
            "Train Epoch: 7 [50880/60000 (85%)]\tLoss: 0.003870\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.085907\n",
            "Train Epoch: 7 [51520/60000 (86%)]\tLoss: 0.000439\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.001949\n",
            "Train Epoch: 7 [52160/60000 (87%)]\tLoss: 0.000549\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.002765\n",
            "Train Epoch: 7 [52800/60000 (88%)]\tLoss: 0.085998\n",
            "Train Epoch: 7 [53120/60000 (89%)]\tLoss: 0.008476\n",
            "Train Epoch: 7 [53440/60000 (89%)]\tLoss: 0.005170\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.001526\n",
            "Train Epoch: 7 [54080/60000 (90%)]\tLoss: 0.000089\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.077026\n",
            "Train Epoch: 7 [54720/60000 (91%)]\tLoss: 0.000141\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.000296\n",
            "Train Epoch: 7 [55360/60000 (92%)]\tLoss: 0.000214\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.047385\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.000044\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.000299\n",
            "Train Epoch: 7 [56640/60000 (94%)]\tLoss: 0.002084\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.000001\n",
            "Train Epoch: 7 [57280/60000 (95%)]\tLoss: 0.019711\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.000194\n",
            "Train Epoch: 7 [57920/60000 (97%)]\tLoss: 0.060200\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.030981\n",
            "Train Epoch: 7 [58560/60000 (98%)]\tLoss: 0.000272\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.000750\n",
            "Train Epoch: 7 [59200/60000 (99%)]\tLoss: 0.005029\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.000366\n",
            "Train Epoch: 7 [59840/60000 (100%)]\tLoss: 0.000568\n",
            "\n",
            "Test set: Average loss: 0.0316, Accuracy: 9912/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.032115\n",
            "Train Epoch: 8 [320/60000 (1%)]\tLoss: 0.003213\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.000326\n",
            "Train Epoch: 8 [960/60000 (2%)]\tLoss: 0.001736\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.000310\n",
            "Train Epoch: 8 [1600/60000 (3%)]\tLoss: 0.006183\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.002798\n",
            "Train Epoch: 8 [2240/60000 (4%)]\tLoss: 0.002115\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.000859\n",
            "Train Epoch: 8 [2880/60000 (5%)]\tLoss: 0.059735\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.002121\n",
            "Train Epoch: 8 [3520/60000 (6%)]\tLoss: 0.000152\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.109153\n",
            "Train Epoch: 8 [4160/60000 (7%)]\tLoss: 0.000047\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.008156\n",
            "Train Epoch: 8 [4800/60000 (8%)]\tLoss: 0.000025\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.011152\n",
            "Train Epoch: 8 [5440/60000 (9%)]\tLoss: 0.000737\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.005582\n",
            "Train Epoch: 8 [6080/60000 (10%)]\tLoss: 0.000710\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.038656\n",
            "Train Epoch: 8 [6720/60000 (11%)]\tLoss: 0.005618\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.005450\n",
            "Train Epoch: 8 [7360/60000 (12%)]\tLoss: 0.000043\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.000312\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.011830\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.000550\n",
            "Train Epoch: 8 [8640/60000 (14%)]\tLoss: 0.004359\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.000344\n",
            "Train Epoch: 8 [9280/60000 (15%)]\tLoss: 0.000065\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.001088\n",
            "Train Epoch: 8 [9920/60000 (17%)]\tLoss: 0.000165\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.000541\n",
            "Train Epoch: 8 [10560/60000 (18%)]\tLoss: 0.000290\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.007786\n",
            "Train Epoch: 8 [11200/60000 (19%)]\tLoss: 0.000016\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.000140\n",
            "Train Epoch: 8 [11840/60000 (20%)]\tLoss: 0.000023\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.000007\n",
            "Train Epoch: 8 [12480/60000 (21%)]\tLoss: 0.000003\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000024\n",
            "Train Epoch: 8 [13120/60000 (22%)]\tLoss: 0.000270\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.000244\n",
            "Train Epoch: 8 [13760/60000 (23%)]\tLoss: 0.000012\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.005182\n",
            "Train Epoch: 8 [14400/60000 (24%)]\tLoss: 0.000216\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.001691\n",
            "Train Epoch: 8 [15040/60000 (25%)]\tLoss: 0.073293\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.003794\n",
            "Train Epoch: 8 [15680/60000 (26%)]\tLoss: 0.000150\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.002954\n",
            "Train Epoch: 8 [16320/60000 (27%)]\tLoss: 0.010583\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.000391\n",
            "Train Epoch: 8 [16960/60000 (28%)]\tLoss: 0.000497\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.001057\n",
            "Train Epoch: 8 [17600/60000 (29%)]\tLoss: 0.000674\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.021894\n",
            "Train Epoch: 8 [18240/60000 (30%)]\tLoss: 0.000307\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.000360\n",
            "Train Epoch: 8 [18880/60000 (31%)]\tLoss: 0.000562\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.002819\n",
            "Train Epoch: 8 [19520/60000 (33%)]\tLoss: 0.000936\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.001438\n",
            "Train Epoch: 8 [20160/60000 (34%)]\tLoss: 0.001661\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.000691\n",
            "Train Epoch: 8 [20800/60000 (35%)]\tLoss: 0.022316\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.001120\n",
            "Train Epoch: 8 [21440/60000 (36%)]\tLoss: 0.007106\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.026297\n",
            "Train Epoch: 8 [22080/60000 (37%)]\tLoss: 0.015621\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.033633\n",
            "Train Epoch: 8 [22720/60000 (38%)]\tLoss: 0.000447\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.003982\n",
            "Train Epoch: 8 [23360/60000 (39%)]\tLoss: 0.000318\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.037886\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.045268\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.030748\n",
            "Train Epoch: 8 [24640/60000 (41%)]\tLoss: 0.011251\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.001088\n",
            "Train Epoch: 8 [25280/60000 (42%)]\tLoss: 0.000177\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.003836\n",
            "Train Epoch: 8 [25920/60000 (43%)]\tLoss: 0.000191\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.000030\n",
            "Train Epoch: 8 [26560/60000 (44%)]\tLoss: 0.078920\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.002911\n",
            "Train Epoch: 8 [27200/60000 (45%)]\tLoss: 0.000327\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.000625\n",
            "Train Epoch: 8 [27840/60000 (46%)]\tLoss: 0.009876\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.000069\n",
            "Train Epoch: 8 [28480/60000 (47%)]\tLoss: 0.000031\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.055234\n",
            "Train Epoch: 8 [29120/60000 (49%)]\tLoss: 0.110545\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.000142\n",
            "Train Epoch: 8 [29760/60000 (50%)]\tLoss: 0.001089\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.000341\n",
            "Train Epoch: 8 [30400/60000 (51%)]\tLoss: 0.003726\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.024424\n",
            "Train Epoch: 8 [31040/60000 (52%)]\tLoss: 0.005829\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.000371\n",
            "Train Epoch: 8 [31680/60000 (53%)]\tLoss: 0.000245\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.002068\n",
            "Train Epoch: 8 [32320/60000 (54%)]\tLoss: 0.000139\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.000221\n",
            "Train Epoch: 8 [32960/60000 (55%)]\tLoss: 0.000590\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.001350\n",
            "Train Epoch: 8 [33600/60000 (56%)]\tLoss: 0.000345\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.006838\n",
            "Train Epoch: 8 [34240/60000 (57%)]\tLoss: 0.024566\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.019019\n",
            "Train Epoch: 8 [34880/60000 (58%)]\tLoss: 0.000057\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.021167\n",
            "Train Epoch: 8 [35520/60000 (59%)]\tLoss: 0.000462\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.000222\n",
            "Train Epoch: 8 [36160/60000 (60%)]\tLoss: 0.034323\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.000086\n",
            "Train Epoch: 8 [36800/60000 (61%)]\tLoss: 0.000755\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.001449\n",
            "Train Epoch: 8 [37440/60000 (62%)]\tLoss: 0.054574\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.000416\n",
            "Train Epoch: 8 [38080/60000 (63%)]\tLoss: 0.011319\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001034\n",
            "Train Epoch: 8 [38720/60000 (65%)]\tLoss: 0.043439\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.000164\n",
            "Train Epoch: 8 [39360/60000 (66%)]\tLoss: 0.003548\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.001670\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.000318\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.000406\n",
            "Train Epoch: 8 [40640/60000 (68%)]\tLoss: 0.148631\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.002075\n",
            "Train Epoch: 8 [41280/60000 (69%)]\tLoss: 0.005104\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.000028\n",
            "Train Epoch: 8 [41920/60000 (70%)]\tLoss: 0.078933\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.083016\n",
            "Train Epoch: 8 [42560/60000 (71%)]\tLoss: 0.098143\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.001362\n",
            "Train Epoch: 8 [43200/60000 (72%)]\tLoss: 0.000898\n",
            "Train Epoch: 8 [43520/60000 (73%)]\tLoss: 0.000491\n",
            "Train Epoch: 8 [43840/60000 (73%)]\tLoss: 0.000011\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.001119\n",
            "Train Epoch: 8 [44480/60000 (74%)]\tLoss: 0.000460\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.068826\n",
            "Train Epoch: 8 [45120/60000 (75%)]\tLoss: 0.032366\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.027969\n",
            "Train Epoch: 8 [45760/60000 (76%)]\tLoss: 0.000301\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.000948\n",
            "Train Epoch: 8 [46400/60000 (77%)]\tLoss: 0.000397\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.000200\n",
            "Train Epoch: 8 [47040/60000 (78%)]\tLoss: 0.003611\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.001125\n",
            "Train Epoch: 8 [47680/60000 (79%)]\tLoss: 0.003857\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.000390\n",
            "Train Epoch: 8 [48320/60000 (81%)]\tLoss: 0.000025\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.014297\n",
            "Train Epoch: 8 [48960/60000 (82%)]\tLoss: 0.039493\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.000587\n",
            "Train Epoch: 8 [49600/60000 (83%)]\tLoss: 0.001443\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.007710\n",
            "Train Epoch: 8 [50240/60000 (84%)]\tLoss: 0.010291\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.000082\n",
            "Train Epoch: 8 [50880/60000 (85%)]\tLoss: 0.040507\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000062\n",
            "Train Epoch: 8 [51520/60000 (86%)]\tLoss: 0.059217\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.000336\n",
            "Train Epoch: 8 [52160/60000 (87%)]\tLoss: 0.068596\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.001756\n",
            "Train Epoch: 8 [52800/60000 (88%)]\tLoss: 0.000032\n",
            "Train Epoch: 8 [53120/60000 (89%)]\tLoss: 0.168190\n",
            "Train Epoch: 8 [53440/60000 (89%)]\tLoss: 0.099679\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.029041\n",
            "Train Epoch: 8 [54080/60000 (90%)]\tLoss: 0.000679\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.000096\n",
            "Train Epoch: 8 [54720/60000 (91%)]\tLoss: 0.000082\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.000223\n",
            "Train Epoch: 8 [55360/60000 (92%)]\tLoss: 0.008529\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.001176\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.003935\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.000955\n",
            "Train Epoch: 8 [56640/60000 (94%)]\tLoss: 0.000040\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.000146\n",
            "Train Epoch: 8 [57280/60000 (95%)]\tLoss: 0.000419\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.008660\n",
            "Train Epoch: 8 [57920/60000 (97%)]\tLoss: 0.001473\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.000009\n",
            "Train Epoch: 8 [58560/60000 (98%)]\tLoss: 0.003584\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.003145\n",
            "Train Epoch: 8 [59200/60000 (99%)]\tLoss: 0.000670\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.000202\n",
            "Train Epoch: 8 [59840/60000 (100%)]\tLoss: 0.000868\n",
            "\n",
            "Test set: Average loss: 0.0246, Accuracy: 9937/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000191\n",
            "Train Epoch: 9 [320/60000 (1%)]\tLoss: 0.000033\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.004627\n",
            "Train Epoch: 9 [960/60000 (2%)]\tLoss: 0.000113\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.003993\n",
            "Train Epoch: 9 [1600/60000 (3%)]\tLoss: 0.001344\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.000097\n",
            "Train Epoch: 9 [2240/60000 (4%)]\tLoss: 0.000122\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.001083\n",
            "Train Epoch: 9 [2880/60000 (5%)]\tLoss: 0.008625\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000852\n",
            "Train Epoch: 9 [3520/60000 (6%)]\tLoss: 0.015977\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.000111\n",
            "Train Epoch: 9 [4160/60000 (7%)]\tLoss: 0.001887\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.000193\n",
            "Train Epoch: 9 [4800/60000 (8%)]\tLoss: 0.013779\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.000232\n",
            "Train Epoch: 9 [5440/60000 (9%)]\tLoss: 0.008850\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.000020\n",
            "Train Epoch: 9 [6080/60000 (10%)]\tLoss: 0.000150\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000016\n",
            "Train Epoch: 9 [6720/60000 (11%)]\tLoss: 0.000011\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.000458\n",
            "Train Epoch: 9 [7360/60000 (12%)]\tLoss: 0.003798\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.000353\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.000046\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.000820\n",
            "Train Epoch: 9 [8640/60000 (14%)]\tLoss: 0.003587\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.000157\n",
            "Train Epoch: 9 [9280/60000 (15%)]\tLoss: 0.009364\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.017322\n",
            "Train Epoch: 9 [9920/60000 (17%)]\tLoss: 0.000910\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.000014\n",
            "Train Epoch: 9 [10560/60000 (18%)]\tLoss: 0.053337\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.000139\n",
            "Train Epoch: 9 [11200/60000 (19%)]\tLoss: 0.007096\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.039119\n",
            "Train Epoch: 9 [11840/60000 (20%)]\tLoss: 0.000013\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.181186\n",
            "Train Epoch: 9 [12480/60000 (21%)]\tLoss: 0.000036\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000484\n",
            "Train Epoch: 9 [13120/60000 (22%)]\tLoss: 0.003121\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.001529\n",
            "Train Epoch: 9 [13760/60000 (23%)]\tLoss: 0.000016\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.004338\n",
            "Train Epoch: 9 [14400/60000 (24%)]\tLoss: 0.000498\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.007662\n",
            "Train Epoch: 9 [15040/60000 (25%)]\tLoss: 0.036049\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.000055\n",
            "Train Epoch: 9 [15680/60000 (26%)]\tLoss: 0.004028\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000313\n",
            "Train Epoch: 9 [16320/60000 (27%)]\tLoss: 0.000056\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.000074\n",
            "Train Epoch: 9 [16960/60000 (28%)]\tLoss: 0.001874\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.000576\n",
            "Train Epoch: 9 [17600/60000 (29%)]\tLoss: 0.000167\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.005163\n",
            "Train Epoch: 9 [18240/60000 (30%)]\tLoss: 0.027463\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.002030\n",
            "Train Epoch: 9 [18880/60000 (31%)]\tLoss: 0.057643\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.003673\n",
            "Train Epoch: 9 [19520/60000 (33%)]\tLoss: 0.000582\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.002866\n",
            "Train Epoch: 9 [20160/60000 (34%)]\tLoss: 0.000421\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.000665\n",
            "Train Epoch: 9 [20800/60000 (35%)]\tLoss: 0.000076\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.062429\n",
            "Train Epoch: 9 [21440/60000 (36%)]\tLoss: 0.001710\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.030597\n",
            "Train Epoch: 9 [22080/60000 (37%)]\tLoss: 0.000207\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.000691\n",
            "Train Epoch: 9 [22720/60000 (38%)]\tLoss: 0.000028\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.000099\n",
            "Train Epoch: 9 [23360/60000 (39%)]\tLoss: 0.000155\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.000061\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.000703\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.004568\n",
            "Train Epoch: 9 [24640/60000 (41%)]\tLoss: 0.000559\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.001356\n",
            "Train Epoch: 9 [25280/60000 (42%)]\tLoss: 0.021433\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.019827\n",
            "Train Epoch: 9 [25920/60000 (43%)]\tLoss: 0.027569\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.001556\n",
            "Train Epoch: 9 [26560/60000 (44%)]\tLoss: 0.010986\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.062900\n",
            "Train Epoch: 9 [27200/60000 (45%)]\tLoss: 0.000099\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.000072\n",
            "Train Epoch: 9 [27840/60000 (46%)]\tLoss: 0.002213\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.000072\n",
            "Train Epoch: 9 [28480/60000 (47%)]\tLoss: 0.000529\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.116663\n",
            "Train Epoch: 9 [29120/60000 (49%)]\tLoss: 0.000796\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.009527\n",
            "Train Epoch: 9 [29760/60000 (50%)]\tLoss: 0.000893\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.000159\n",
            "Train Epoch: 9 [30400/60000 (51%)]\tLoss: 0.000378\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.000007\n",
            "Train Epoch: 9 [31040/60000 (52%)]\tLoss: 0.000136\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.013666\n",
            "Train Epoch: 9 [31680/60000 (53%)]\tLoss: 0.000020\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000543\n",
            "Train Epoch: 9 [32320/60000 (54%)]\tLoss: 0.000521\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.000222\n",
            "Train Epoch: 9 [32960/60000 (55%)]\tLoss: 0.084262\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.039284\n",
            "Train Epoch: 9 [33600/60000 (56%)]\tLoss: 0.165624\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.000021\n",
            "Train Epoch: 9 [34240/60000 (57%)]\tLoss: 0.002388\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.051784\n",
            "Train Epoch: 9 [34880/60000 (58%)]\tLoss: 0.000274\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.000042\n",
            "Train Epoch: 9 [35520/60000 (59%)]\tLoss: 0.003470\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.002862\n",
            "Train Epoch: 9 [36160/60000 (60%)]\tLoss: 0.004073\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.000662\n",
            "Train Epoch: 9 [36800/60000 (61%)]\tLoss: 0.017129\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.001129\n",
            "Train Epoch: 9 [37440/60000 (62%)]\tLoss: 0.005525\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.022733\n",
            "Train Epoch: 9 [38080/60000 (63%)]\tLoss: 0.000577\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.009464\n",
            "Train Epoch: 9 [38720/60000 (65%)]\tLoss: 0.002851\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.000158\n",
            "Train Epoch: 9 [39360/60000 (66%)]\tLoss: 0.000032\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.003062\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.000667\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.001598\n",
            "Train Epoch: 9 [40640/60000 (68%)]\tLoss: 0.000089\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.000444\n",
            "Train Epoch: 9 [41280/60000 (69%)]\tLoss: 0.009419\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.016391\n",
            "Train Epoch: 9 [41920/60000 (70%)]\tLoss: 0.000228\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.001344\n",
            "Train Epoch: 9 [42560/60000 (71%)]\tLoss: 0.000169\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.107238\n",
            "Train Epoch: 9 [43200/60000 (72%)]\tLoss: 0.137026\n",
            "Train Epoch: 9 [43520/60000 (73%)]\tLoss: 0.000483\n",
            "Train Epoch: 9 [43840/60000 (73%)]\tLoss: 0.000218\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.252049\n",
            "Train Epoch: 9 [44480/60000 (74%)]\tLoss: 0.000955\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.057145\n",
            "Train Epoch: 9 [45120/60000 (75%)]\tLoss: 0.001781\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.000717\n",
            "Train Epoch: 9 [45760/60000 (76%)]\tLoss: 0.004817\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.058617\n",
            "Train Epoch: 9 [46400/60000 (77%)]\tLoss: 0.000375\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.000029\n",
            "Train Epoch: 9 [47040/60000 (78%)]\tLoss: 0.001320\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.001752\n",
            "Train Epoch: 9 [47680/60000 (79%)]\tLoss: 0.000501\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.000275\n",
            "Train Epoch: 9 [48320/60000 (81%)]\tLoss: 0.000886\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.004107\n",
            "Train Epoch: 9 [48960/60000 (82%)]\tLoss: 0.000002\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.000627\n",
            "Train Epoch: 9 [49600/60000 (83%)]\tLoss: 0.003276\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.002820\n",
            "Train Epoch: 9 [50240/60000 (84%)]\tLoss: 0.000005\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.001173\n",
            "Train Epoch: 9 [50880/60000 (85%)]\tLoss: 0.000075\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.004199\n",
            "Train Epoch: 9 [51520/60000 (86%)]\tLoss: 0.038628\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.023167\n",
            "Train Epoch: 9 [52160/60000 (87%)]\tLoss: 0.000062\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.000189\n",
            "Train Epoch: 9 [52800/60000 (88%)]\tLoss: 0.011388\n",
            "Train Epoch: 9 [53120/60000 (89%)]\tLoss: 0.001500\n",
            "Train Epoch: 9 [53440/60000 (89%)]\tLoss: 0.000005\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.000040\n",
            "Train Epoch: 9 [54080/60000 (90%)]\tLoss: 0.001742\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.000041\n",
            "Train Epoch: 9 [54720/60000 (91%)]\tLoss: 0.000869\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.001663\n",
            "Train Epoch: 9 [55360/60000 (92%)]\tLoss: 0.000099\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.000021\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.000289\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.000235\n",
            "Train Epoch: 9 [56640/60000 (94%)]\tLoss: 0.000116\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.000075\n",
            "Train Epoch: 9 [57280/60000 (95%)]\tLoss: 0.000085\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000350\n",
            "Train Epoch: 9 [57920/60000 (97%)]\tLoss: 0.029069\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.012333\n",
            "Train Epoch: 9 [58560/60000 (98%)]\tLoss: 0.007492\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.001038\n",
            "Train Epoch: 9 [59200/60000 (99%)]\tLoss: 0.000004\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.003218\n",
            "Train Epoch: 9 [59840/60000 (100%)]\tLoss: 0.000170\n",
            "\n",
            "Test set: Average loss: 0.0323, Accuracy: 9910/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.009157\n",
            "Train Epoch: 10 [320/60000 (1%)]\tLoss: 0.000025\n",
            "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.000089\n",
            "Train Epoch: 10 [960/60000 (2%)]\tLoss: 0.000016\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.000050\n",
            "Train Epoch: 10 [1600/60000 (3%)]\tLoss: 0.009125\n",
            "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.000249\n",
            "Train Epoch: 10 [2240/60000 (4%)]\tLoss: 0.000295\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.000028\n",
            "Train Epoch: 10 [2880/60000 (5%)]\tLoss: 0.052554\n",
            "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.000275\n",
            "Train Epoch: 10 [3520/60000 (6%)]\tLoss: 0.000807\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.015254\n",
            "Train Epoch: 10 [4160/60000 (7%)]\tLoss: 0.019726\n",
            "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.000044\n",
            "Train Epoch: 10 [4800/60000 (8%)]\tLoss: 0.000694\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.000042\n",
            "Train Epoch: 10 [5440/60000 (9%)]\tLoss: 0.000036\n",
            "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.002319\n",
            "Train Epoch: 10 [6080/60000 (10%)]\tLoss: 0.000034\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.018329\n",
            "Train Epoch: 10 [6720/60000 (11%)]\tLoss: 0.000017\n",
            "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.000007\n",
            "Train Epoch: 10 [7360/60000 (12%)]\tLoss: 0.000111\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.002155\n",
            "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.003541\n",
            "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.000681\n",
            "Train Epoch: 10 [8640/60000 (14%)]\tLoss: 0.000995\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.000502\n",
            "Train Epoch: 10 [9280/60000 (15%)]\tLoss: 0.004566\n",
            "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.000060\n",
            "Train Epoch: 10 [9920/60000 (17%)]\tLoss: 0.000908\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.000009\n",
            "Train Epoch: 10 [10560/60000 (18%)]\tLoss: 0.161812\n",
            "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.000334\n",
            "Train Epoch: 10 [11200/60000 (19%)]\tLoss: 0.000047\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.000075\n",
            "Train Epoch: 10 [11840/60000 (20%)]\tLoss: 0.010346\n",
            "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.000809\n",
            "Train Epoch: 10 [12480/60000 (21%)]\tLoss: 0.002253\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.038473\n",
            "Train Epoch: 10 [13120/60000 (22%)]\tLoss: 0.010653\n",
            "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.000005\n",
            "Train Epoch: 10 [13760/60000 (23%)]\tLoss: 0.001218\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.000162\n",
            "Train Epoch: 10 [14400/60000 (24%)]\tLoss: 0.002164\n",
            "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.001865\n",
            "Train Epoch: 10 [15040/60000 (25%)]\tLoss: 0.030861\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.000196\n",
            "Train Epoch: 10 [15680/60000 (26%)]\tLoss: 0.000107\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.013231\n",
            "Train Epoch: 10 [16320/60000 (27%)]\tLoss: 0.000027\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.000215\n",
            "Train Epoch: 10 [16960/60000 (28%)]\tLoss: 0.000636\n",
            "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.001964\n",
            "Train Epoch: 10 [17600/60000 (29%)]\tLoss: 0.000209\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [18240/60000 (30%)]\tLoss: 0.001840\n",
            "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.182230\n",
            "Train Epoch: 10 [18880/60000 (31%)]\tLoss: 0.013550\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.004261\n",
            "Train Epoch: 10 [19520/60000 (33%)]\tLoss: 0.000093\n",
            "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.093834\n",
            "Train Epoch: 10 [20160/60000 (34%)]\tLoss: 0.036345\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.000053\n",
            "Train Epoch: 10 [20800/60000 (35%)]\tLoss: 0.000449\n",
            "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.000043\n",
            "Train Epoch: 10 [21440/60000 (36%)]\tLoss: 0.000390\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.000008\n",
            "Train Epoch: 10 [22080/60000 (37%)]\tLoss: 0.043106\n",
            "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.003303\n",
            "Train Epoch: 10 [22720/60000 (38%)]\tLoss: 0.000008\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.000074\n",
            "Train Epoch: 10 [23360/60000 (39%)]\tLoss: 0.000022\n",
            "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.000537\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.000665\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.000002\n",
            "Train Epoch: 10 [24640/60000 (41%)]\tLoss: 0.000810\n",
            "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.000716\n",
            "Train Epoch: 10 [25280/60000 (42%)]\tLoss: 0.006292\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.009520\n",
            "Train Epoch: 10 [25920/60000 (43%)]\tLoss: 0.000024\n",
            "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.000604\n",
            "Train Epoch: 10 [26560/60000 (44%)]\tLoss: 0.001884\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.000318\n",
            "Train Epoch: 10 [27200/60000 (45%)]\tLoss: 0.000051\n",
            "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.001854\n",
            "Train Epoch: 10 [27840/60000 (46%)]\tLoss: 0.000005\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.000051\n",
            "Train Epoch: 10 [28480/60000 (47%)]\tLoss: 0.000948\n",
            "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.004847\n",
            "Train Epoch: 10 [29120/60000 (49%)]\tLoss: 0.000021\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.000175\n",
            "Train Epoch: 10 [29760/60000 (50%)]\tLoss: 0.000027\n",
            "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.000305\n",
            "Train Epoch: 10 [30400/60000 (51%)]\tLoss: 0.003501\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.000028\n",
            "Train Epoch: 10 [31040/60000 (52%)]\tLoss: 0.000022\n",
            "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.000542\n",
            "Train Epoch: 10 [31680/60000 (53%)]\tLoss: 0.011933\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.016814\n",
            "Train Epoch: 10 [32320/60000 (54%)]\tLoss: 0.000003\n",
            "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.000122\n",
            "Train Epoch: 10 [32960/60000 (55%)]\tLoss: 0.000003\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.000038\n",
            "Train Epoch: 10 [33600/60000 (56%)]\tLoss: 0.000001\n",
            "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.000103\n",
            "Train Epoch: 10 [34240/60000 (57%)]\tLoss: 0.000418\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.006737\n",
            "Train Epoch: 10 [34880/60000 (58%)]\tLoss: 0.000694\n",
            "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.095593\n",
            "Train Epoch: 10 [35520/60000 (59%)]\tLoss: 0.000279\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.000310\n",
            "Train Epoch: 10 [36160/60000 (60%)]\tLoss: 0.005989\n",
            "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.000116\n",
            "Train Epoch: 10 [36800/60000 (61%)]\tLoss: 0.025719\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.004162\n",
            "Train Epoch: 10 [37440/60000 (62%)]\tLoss: 0.001683\n",
            "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.013224\n",
            "Train Epoch: 10 [38080/60000 (63%)]\tLoss: 0.000578\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000193\n",
            "Train Epoch: 10 [38720/60000 (65%)]\tLoss: 0.019274\n",
            "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.000008\n",
            "Train Epoch: 10 [39360/60000 (66%)]\tLoss: 0.266734\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.000330\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.000006\n",
            "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.001950\n",
            "Train Epoch: 10 [40640/60000 (68%)]\tLoss: 0.005618\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.000240\n",
            "Train Epoch: 10 [41280/60000 (69%)]\tLoss: 0.002203\n",
            "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.000089\n",
            "Train Epoch: 10 [41920/60000 (70%)]\tLoss: 0.002561\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.053204\n",
            "Train Epoch: 10 [42560/60000 (71%)]\tLoss: 0.000026\n",
            "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.000896\n",
            "Train Epoch: 10 [43200/60000 (72%)]\tLoss: 0.001961\n",
            "Train Epoch: 10 [43520/60000 (73%)]\tLoss: 0.000010\n",
            "Train Epoch: 10 [43840/60000 (73%)]\tLoss: 0.000086\n",
            "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.028959\n",
            "Train Epoch: 10 [44480/60000 (74%)]\tLoss: 0.000341\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.000174\n",
            "Train Epoch: 10 [45120/60000 (75%)]\tLoss: 0.000011\n",
            "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.000418\n",
            "Train Epoch: 10 [45760/60000 (76%)]\tLoss: 0.004224\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.001554\n",
            "Train Epoch: 10 [46400/60000 (77%)]\tLoss: 0.000241\n",
            "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.017779\n",
            "Train Epoch: 10 [47040/60000 (78%)]\tLoss: 0.016613\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.015139\n",
            "Train Epoch: 10 [47680/60000 (79%)]\tLoss: 0.000026\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.000459\n",
            "Train Epoch: 10 [48320/60000 (81%)]\tLoss: 0.000504\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.001620\n",
            "Train Epoch: 10 [48960/60000 (82%)]\tLoss: 0.002163\n",
            "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.002901\n",
            "Train Epoch: 10 [49600/60000 (83%)]\tLoss: 0.082809\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.015039\n",
            "Train Epoch: 10 [50240/60000 (84%)]\tLoss: 0.003921\n",
            "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.000262\n",
            "Train Epoch: 10 [50880/60000 (85%)]\tLoss: 0.005384\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000141\n",
            "Train Epoch: 10 [51520/60000 (86%)]\tLoss: 0.002876\n",
            "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.079482\n",
            "Train Epoch: 10 [52160/60000 (87%)]\tLoss: 0.000163\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.000429\n",
            "Train Epoch: 10 [52800/60000 (88%)]\tLoss: 0.000315\n",
            "Train Epoch: 10 [53120/60000 (89%)]\tLoss: 0.000031\n",
            "Train Epoch: 10 [53440/60000 (89%)]\tLoss: 0.001429\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.000132\n",
            "Train Epoch: 10 [54080/60000 (90%)]\tLoss: 0.005952\n",
            "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.000113\n",
            "Train Epoch: 10 [54720/60000 (91%)]\tLoss: 0.000065\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.021593\n",
            "Train Epoch: 10 [55360/60000 (92%)]\tLoss: 0.000010\n",
            "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.004472\n",
            "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.001160\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.004115\n",
            "Train Epoch: 10 [56640/60000 (94%)]\tLoss: 0.000130\n",
            "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.000049\n",
            "Train Epoch: 10 [57280/60000 (95%)]\tLoss: 0.002839\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.000011\n",
            "Train Epoch: 10 [57920/60000 (97%)]\tLoss: 0.000874\n",
            "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.000942\n",
            "Train Epoch: 10 [58560/60000 (98%)]\tLoss: 0.015869\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.000121\n",
            "Train Epoch: 10 [59200/60000 (99%)]\tLoss: 0.002059\n",
            "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.000050\n",
            "Train Epoch: 10 [59840/60000 (100%)]\tLoss: 0.000255\n",
            "\n",
            "Test set: Average loss: 0.0359, Accuracy: 9899/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Results - lr = 1, epochs = 10, batch_size = 64  "
      ],
      "metadata": {
        "id": "lG6D3vXRnGnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1, momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2gZgaA8anhkD",
        "outputId": "19fb6f5e-982c-4ee9-8cd0-388e8d151a4a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.340626\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.621990\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.327994\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.329976\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.336680\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.313088\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.318086\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.303602\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.281194\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.307733\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.295525\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.291606\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.293540\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.309397\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.319022\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.320952\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.307073\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.319166\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.301012\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.311115\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.347541\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.319954\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.313705\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.311377\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.298908\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.284152\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.311716\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.292705\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.300225\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.338836\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.321060\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.325031\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.295153\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.322743\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.304688\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.316061\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.330109\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.319218\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.300925\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.300589\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.323163\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.305424\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.329230\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.317708\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.298838\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.323270\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.304635\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.308390\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.317737\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.301744\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.345844\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.316193\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.291177\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.306459\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.305795\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.315194\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.274100\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.307248\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.327585\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.325496\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.306679\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.315148\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.307068\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.292766\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.308642\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.331356\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.281924\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.302131\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.292247\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.299639\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.330626\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.284778\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.307819\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.310534\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.309284\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.287242\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.318490\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.306517\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.271954\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.314415\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.295055\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 2.304059\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.314345\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 2.292445\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.281587\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.292534\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.329124\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 2.308108\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.287612\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 2.285433\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.269003\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 2.290024\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.309281\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 2.281935\n",
            "\n",
            "Test set: Average loss: 2.3087, Accuracy: 958/10000 (10%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.330287\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 2.314230\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.320301\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 2.304513\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.296660\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 2.282573\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.290595\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 2.310052\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.285253\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 2.300413\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.302020\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 2.304285\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.270161\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 2.289737\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 2.331856\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 2.311740\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.301803\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 2.332362\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.314059\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 2.301548\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.326883\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 2.298704\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 2.321841\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 2.306731\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 2.314513\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.271297\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 2.302706\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 2.273158\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 2.297009\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 2.311208\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.328765\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 2.298674\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 2.338968\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 2.326336\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 2.326638\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 2.295879\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 2.335397\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 2.317883\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 2.309038\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 2.335159\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.308511\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 2.300233\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 2.324417\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 2.321272\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 2.322507\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 2.321053\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 2.307353\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 2.303596\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 2.316482\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 2.304222\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.290196\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 2.281465\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 2.306686\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 2.291667\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 2.315766\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 2.315135\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 2.302395\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 2.307746\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 2.285723\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 2.325013\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.315194\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 2.336312\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 2.289247\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 2.316560\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 2.308459\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 2.326386\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 2.294385\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 2.287133\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 2.270760\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 2.340415\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.319701\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 2.290442\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 2.327984\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 2.302638\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 2.310223\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.291643\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 2.308290\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 2.284235\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 2.309350\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 2.324389\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.311144\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 2.312025\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 2.321984\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 2.309374\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 2.306270\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 2.353720\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 2.306987\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 2.302335\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 2.303996\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 2.312654\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 2.310192\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 2.305124\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 2.309918\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 2.294675\n",
            "\n",
            "Test set: Average loss: 2.3080, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.308063\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 2.316544\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 2.295970\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 2.293710\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 2.281904\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 2.318519\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 2.287595\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 2.297194\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 2.283691\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 2.313542\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 2.302351\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 2.346611\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 2.306898\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 2.301236\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 2.301106\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 2.300156\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 2.283269\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 2.284044\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 2.304854\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 2.305402\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.319438\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 2.316293\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 2.321563\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 2.297969\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 2.306751\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.292745\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 2.323133\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 2.309559\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 2.303255\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 2.317107\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 2.313392\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 2.311560\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 2.297405\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 2.287569\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 2.300295\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 2.296844\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 2.305580\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 2.283753\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 2.336982\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 2.300002\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.313901\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 2.320390\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 2.325094\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 2.299162\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 2.320614\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 2.281283\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 2.308289\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 2.304824\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 2.319154\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 2.286764\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.298982\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 2.326965\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 2.318033\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 2.290424\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 2.300429\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 2.312919\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 2.309400\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 2.296597\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 2.331815\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 2.321283\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.288120\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 2.297087\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 2.300987\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 2.286957\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 2.306586\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 2.302927\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 2.321383\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 2.306301\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 2.303737\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 2.294377\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.310096\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 2.304807\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 2.318000\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 2.306962\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 2.313616\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.310808\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 2.282543\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 2.298391\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 2.292288\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 2.307241\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.294302\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 2.314032\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 2.306762\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 2.308526\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 2.294450\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 2.281323\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 2.298948\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 2.313339\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 2.298926\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 2.295160\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 2.304868\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 2.299443\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 2.275982\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 2.293298\n",
            "\n",
            "Test set: Average loss: 2.3037, Accuracy: 1028/10000 (10%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.305300\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 2.319840\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 2.301977\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 2.318312\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 2.300312\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 2.289047\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 2.334547\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 2.307252\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 2.320839\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 2.287389\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 2.287091\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 2.303629\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 2.299389\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 2.317691\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 2.325883\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 2.294132\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 2.327231\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 2.313073\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 2.306097\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 2.275707\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.336035\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 2.301252\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 2.314276\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 2.291602\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 2.321530\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.325016\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 2.300791\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 2.314761\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 2.311628\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 2.274928\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 2.298218\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 2.327298\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 2.307982\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 2.328115\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 2.306493\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 2.293272\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 2.320962\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 2.290761\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 2.303838\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 2.315488\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.313031\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 2.300842\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 2.324016\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 2.301229\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 2.303953\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 2.296064\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 2.292318\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 2.268100\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 2.289441\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 2.292859\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.291265\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 2.336643\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 2.295920\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 2.331297\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 2.311603\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 2.274053\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 2.309768\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 2.272903\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 2.306252\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 2.328342\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.314909\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 2.322205\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 2.286402\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 2.292433\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 2.322520\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 2.307120\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 2.285675\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 2.330161\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 2.338853\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 2.308386\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 2.266879\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 2.262220\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 2.320411\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 2.285827\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 2.295575\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.305003\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 2.305680\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 2.290722\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 2.302486\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 2.285101\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.309444\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 2.294127\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 2.318772\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 2.309533\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 2.312524\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 2.281597\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 2.318321\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 2.315543\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 2.326980\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 2.303389\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 2.286958\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 2.315412\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 2.308069\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 2.312977\n",
            "\n",
            "Test set: Average loss: 2.3096, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.322343\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 2.290533\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 2.297138\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 2.315381\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 2.296952\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 2.288811\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 2.308021\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 2.282460\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 2.321949\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 2.305050\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 2.304453\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 2.306813\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 2.324300\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 2.312715\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 2.298535\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 2.285171\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 2.304950\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 2.305042\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 2.322828\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 2.271650\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.336379\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 2.310188\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 2.309675\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 2.339455\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 2.289382\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.331897\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 2.322043\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 2.300364\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 2.321867\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 2.309834\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 2.300274\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 2.313654\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 2.331811\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 2.281492\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 2.321696\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 2.296071\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 2.342225\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 2.331508\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 2.305065\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 2.291806\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.321716\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 2.299061\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 2.334871\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 2.307814\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 2.293389\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 2.324129\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 2.320732\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 2.293812\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 2.338198\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 2.298101\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.314860\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 2.319455\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 2.304342\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 2.281019\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 2.314451\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 2.321890\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 2.333680\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 2.298733\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 2.297550\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 2.306856\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.300390\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 2.317867\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 2.338598\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 2.299668\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 2.294734\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 2.302395\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 2.310078\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 2.287136\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 2.292536\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 2.332253\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 2.293064\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 2.313195\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 2.298337\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 2.330383\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 2.297109\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.284661\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 2.316596\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 2.293657\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 2.309162\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 2.315144\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.305004\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 2.295874\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 2.274687\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 2.323462\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 2.318370\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 2.322174\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 2.306247\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 2.287434\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 2.304174\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 2.301397\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 2.306953\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 2.319144\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 2.307681\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 2.275379\n",
            "\n",
            "Test set: Average loss: 2.3069, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.270384\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 2.314703\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 2.306242\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 2.325038\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 2.288419\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 2.301712\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 2.329504\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 2.295793\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 2.301471\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 2.300446\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 2.285546\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 2.302375\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 2.305593\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 2.295365\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 2.336606\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 2.285109\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 2.313798\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 2.322571\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 2.298686\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 2.312221\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 2.309264\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 2.312376\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 2.296361\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 2.293822\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 2.298537\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.298702\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 2.324060\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 2.322969\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 2.303999\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 2.303425\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 2.299783\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 2.319896\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 2.287224\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 2.299354\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 2.297287\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 2.280504\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 2.339435\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 2.341175\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 2.314598\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 2.296941\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 2.319571\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 2.304109\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 2.324870\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 2.315820\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 2.310772\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 2.304991\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 2.344947\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 2.305032\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 2.347616\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 2.286948\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.327223\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 2.310138\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 2.309167\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 2.311120\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 2.337568\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 2.302471\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 2.296858\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 2.290640\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 2.307055\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 2.346024\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 2.304389\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 2.299378\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 2.306795\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 2.323019\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 2.319686\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 2.293260\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 2.288957\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 2.303880\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 2.366743\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 2.300243\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 2.316298\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 2.305503\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 2.291377\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 2.300796\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 2.294852\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.315223\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 2.333318\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 2.318192\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 2.323403\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 2.315268\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 2.317907\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 2.285584\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 2.301947\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 2.315882\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 2.286048\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 2.305185\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 2.320237\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 2.284355\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 2.304811\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 2.334470\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 2.297980\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 2.320023\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 2.298394\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 2.340439\n",
            "\n",
            "Test set: Average loss: 2.3178, Accuracy: 974/10000 (10%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.297621\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 2.307267\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 2.287900\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 2.284731\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 2.316417\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 2.300205\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 2.326584\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 2.286003\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 2.295331\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 2.304598\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 2.324364\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 2.283191\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 2.315536\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 2.305325\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 2.279518\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 2.316079\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 2.302330\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 2.303978\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 2.321104\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 2.258891\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 2.284657\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 2.305016\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 2.309281\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 2.280264\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 2.297897\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.280303\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 2.309673\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 2.338791\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 2.371280\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 2.328430\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 2.347622\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 2.311787\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 2.299510\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 2.316989\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 2.327643\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 2.296348\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 2.297512\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 2.312677\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 2.306834\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 2.316577\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 2.305959\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 2.305081\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 2.293937\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 2.313899\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 2.303452\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 2.361521\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 2.296046\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 2.322297\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 2.349014\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 2.290675\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.293877\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 2.308529\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 2.288685\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 2.294549\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 2.296208\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 2.330707\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 2.290835\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 2.290171\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 2.278822\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 2.305955\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 2.308511\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 2.343026\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 2.308788\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 2.305695\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 2.310627\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 2.287569\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 2.320149\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 2.378434\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 2.256075\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 2.324219\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 2.292196\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 2.314569\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 2.321840\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 2.320436\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 2.337174\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.317572\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 2.317368\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 2.327119\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 2.293577\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 2.308803\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 2.304997\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 2.288716\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 2.296829\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 2.317699\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 2.294706\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 2.316430\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 2.315959\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 2.299698\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 2.313489\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 2.294169\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 2.296679\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 2.313251\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 2.306670\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 2.302169\n",
            "\n",
            "Test set: Average loss: 2.3110, Accuracy: 958/10000 (10%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.318971\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 2.333894\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 2.314486\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 2.297585\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 2.295564\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 2.306336\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 2.346560\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 2.322047\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 2.319490\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 2.303326\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 2.306444\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 2.309018\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 2.304483\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 2.299721\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 2.302294\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 2.316077\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 2.279896\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 2.303656\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 2.309375\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 2.358831\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 2.314463\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 2.318135\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 2.318759\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 2.322915\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 2.305074\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.327930\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 2.293937\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 2.303219\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 2.309169\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 2.303633\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 2.336339\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 2.296523\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 2.306273\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 2.319279\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 2.273790\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 2.321262\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 2.322017\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 2.286951\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 2.297985\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 2.298357\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 2.337469\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 2.294181\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 2.328955\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 2.314620\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 2.295153\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 2.312956\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 2.305166\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 2.318224\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 2.293691\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 2.313213\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.303200\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 2.294557\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 2.313231\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 2.298041\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 2.301272\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 2.318063\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 2.320298\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 2.314186\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 2.304204\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 2.296417\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 2.284998\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 2.295341\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 2.317320\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 2.289863\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 2.299274\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 2.312896\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 2.317119\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 2.274047\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 2.325270\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 2.321190\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 2.296877\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 2.331409\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 2.337222\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 2.292273\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 2.333072\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.286078\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 2.293242\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 2.304732\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 2.294833\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 2.297168\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 2.326454\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 2.331041\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 2.302211\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 2.283217\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 2.284396\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 2.282485\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 2.296305\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 2.317375\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 2.319308\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 2.293566\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 2.294475\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 2.313329\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 2.314126\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 2.326155\n",
            "\n",
            "Test set: Average loss: 2.3077, Accuracy: 1010/10000 (10%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.308423\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 2.299148\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 2.276868\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 2.297444\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 2.316800\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 2.301887\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 2.314168\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 2.322171\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 2.299161\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 2.329165\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 2.301268\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 2.303425\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 2.348347\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 2.327452\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 2.302572\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 2.298544\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 2.303571\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 2.339340\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 2.320579\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 2.294270\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 2.307606\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 2.311667\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 2.320864\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 2.304428\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 2.292857\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.316219\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 2.318583\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 2.283163\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 2.287822\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 2.308427\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 2.324300\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 2.337402\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 2.296688\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 2.311247\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 2.301673\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 2.307252\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 2.320422\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 2.300777\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 2.299716\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 2.306449\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 2.309888\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 2.315896\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 2.345569\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 2.298368\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 2.307767\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 2.289544\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 2.351495\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 2.315044\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 2.316817\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 2.328979\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.316836\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 2.290363\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 2.297301\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 2.309552\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 2.298328\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 2.305951\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 2.302052\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 2.285733\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 2.285157\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 2.320795\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 2.319939\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 2.307525\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 2.277639\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 2.283030\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 2.319557\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 2.325118\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 2.298588\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 2.299627\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 2.323462\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 2.302002\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 2.318411\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 2.306325\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 2.319197\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 2.296939\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 2.323881\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.298870\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 2.329995\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 2.330457\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 2.301792\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 2.307408\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 2.359694\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 2.294879\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 2.289260\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 2.286849\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 2.297605\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 2.341166\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 2.304563\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 2.312037\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 2.293014\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 2.288787\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 2.327121\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 2.308062\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 2.258462\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 2.308196\n",
            "\n",
            "Test set: Average loss: 2.3122, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.289145\n",
            "Train Epoch: 10 [640/60000 (1%)]\tLoss: 2.337178\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 2.330881\n",
            "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 2.332503\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 2.318146\n",
            "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 2.319649\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 2.326135\n",
            "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 2.273471\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 2.318339\n",
            "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 2.316772\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 2.286792\n",
            "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 2.305259\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 2.301169\n",
            "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 2.307930\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 2.302467\n",
            "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 2.283033\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 2.324978\n",
            "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 2.355698\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 2.329581\n",
            "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 2.315269\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 2.313777\n",
            "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 2.313977\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 2.307962\n",
            "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 2.303006\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 2.309338\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.296852\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 2.294832\n",
            "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 2.334285\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 2.301759\n",
            "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 2.316252\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 2.298669\n",
            "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 2.318007\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 2.289507\n",
            "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 2.322510\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 2.338709\n",
            "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 2.319637\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 2.307960\n",
            "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 2.311442\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 2.307305\n",
            "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 2.319149\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 2.317187\n",
            "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 2.319272\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 2.337362\n",
            "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 2.303521\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 2.295706\n",
            "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 2.290736\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 2.263722\n",
            "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 2.299443\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 2.307949\n",
            "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 2.337717\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.343166\n",
            "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 2.311043\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 2.322598\n",
            "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 2.358845\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 2.303952\n",
            "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 2.329000\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 2.326202\n",
            "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 2.327387\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 2.314527\n",
            "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 2.305087\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 2.317450\n",
            "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 2.314608\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 2.295364\n",
            "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 2.336642\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 2.305166\n",
            "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 2.298486\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 2.301329\n",
            "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 2.291651\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 2.311035\n",
            "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 2.286532\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 2.325596\n",
            "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 2.305217\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 2.301997\n",
            "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 2.305759\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 2.282578\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.296594\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 2.323181\n",
            "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 2.306249\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 2.294948\n",
            "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 2.305153\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 2.307193\n",
            "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 2.292628\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 2.300191\n",
            "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 2.312104\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 2.281553\n",
            "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 2.331201\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 2.310363\n",
            "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 2.304980\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 2.314329\n",
            "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 2.311706\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 2.313994\n",
            "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 2.323484\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 2.297999\n",
            "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 2.308561\n",
            "\n",
            "Test set: Average loss: 2.3128, Accuracy: 1009/10000 (10%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.   Through the experiment, what is the best configuration?\n",
        "Through experimentation, the best-performing configuration included two convolutional layers followed by two fully connected layers. This setup was further optimized with the following hyperparameters:\n",
        "\n",
        "*   Learning Rate: 0.05\n",
        "*   Batch Size: 32\n",
        "*   Epochs: 10\n",
        "\n",
        "This configuration achieved the highest test accuracy at 98% and the lowest test loss.\n",
        "\n",
        "* **Two Convolutional Layers:** By using two convolutional layers, the network\n",
        "could better capture both low-level features (like edges and textures) and higher-level patterns (like curves and shapes). This made it more capable of distinguishing between visually similar digits. Adding layers improved the models capacity without significantly increasing the risk of overfitting, as each layer was still focused on extracting different levels of spatial hierarchies.\n",
        "\n",
        "* **Learning Rate:** A learning rate of 0.05 enabled efficient and stable learning. An excessively high learning rate would risk overshooting optimal parameters, potentially leading to underfitting, while a lower rate could cause slow convergence or even overfitting as it memorizes instead of generalizing.\n",
        "\n",
        "* **Batch Size and Epochs:** The combination of a smaller batch size (32) and more epochs (10) allowed for frequent parameter updates and enough cycles for convergence without excessive training, which could lead to overfitting.\n",
        "\n",
        "# 2.   What prediction accuracy on the test set you got?\n",
        "Using this optimized configuration, the test set accuracy reached 98%, which was an improvement over the initial configuration with only fully connected layers that achieved 93%. Observing this accuracy on unseen data suggests that the model generalized well, as it avoided common pitfalls like overfitting, where a model performs well on training data but poorly on test data.\n",
        "\n",
        "* **Overfitting:** In this case, the model showed resilience against overfitting despite the added layers. This may be due to the structured architecture of CNNs, which are less prone to overfitting compared to fully connected networks, especially for image tasks. Convolutional layers apply weight sharing and pooling, making the model learn spatial hierarchies instead of memorizing individual pixels.\n",
        "\n",
        "* **Underfitting:** Initially, the simpler model (with only fully connected layers) exhibited signs of underfitting. It struggled to capture the complex patterns necessary for digit recognition, resulting in a lower test accuracy. Adding convolutional layers helped mitigate this issue by enabling the model to learn a broader range of features, ultimately improving test performance.\n",
        "\n",
        "# 3.   What did you learn?\n",
        "This experiment underlined several fundamental machine learning principles such as below:\n",
        "\n",
        "* **Effectiveness of CNN Layers:** Adding convolutional layers significantly improved the model's ability to capture features in the MNIST images, leading to higher accuracy compared to a model with only fully connected layers.\n",
        "\n",
        "* **Hyperparameter Tuning:** The optimal combination of learning rate, batch size, and the number of epochs played a crucial role in achieving the best results. For example, increasing the number of epochs and using a smaller batch size allowed the model to learn the data distribution better.\n",
        "\n",
        "* **Importance of Experimentation:** Testing different network topologies and hyperparameters demonstrated how small adjustments can lead to significant improvements in accuracy, underscoring the importance of experimentation in model optimization.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W2liub4iE-8U"
      }
    }
  ]
}